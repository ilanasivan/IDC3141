{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6bd0516e7cb654f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "# Exercise 2: Decision Trees\n",
    "\n",
    "In this assignment you will implement a Decision Tree algorithm as learned in class.\n",
    "\n",
    "## Read the following instructions carefully:\n",
    "\n",
    "1. This jupyter notebook contains all the step by step instructions needed for this exercise.\n",
    "1. Submission includes this notebook only with the exercise number and your ID as the filename. For example: `hw2_123456789_987654321.ipynb` if you submitted in pairs and `hw2_123456789.ipynb` if you submitted the exercise alone.\n",
    "1. Write **efficient vectorized** code whenever possible. Some calculations in this exercise take several minutes when implemented efficiently, and might take much longer otherwise. Unnecessary loops will result in point deduction.\n",
    "1. You are responsible for the correctness of your code and should add as many tests as you see fit. Tests will not be graded nor checked.\n",
    "1. Write your functions in this notebook only. **Do not create Python modules and import them**.\n",
    "1. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/) and [numpy](https://www.numpy.org/devdocs/reference/) only. **Do not import anything else.**\n",
    "1. Your code must run without errors. Make sure your `numpy` version is at least 1.15.4 and that you are using at least python 3.6. Changes of the configuration we provided are at your own risk. Any code that cannot run will not be graded.\n",
    "1. Write your own code. Cheating will not be tolerated.\n",
    "1. Answers to qualitative questions should be written in **markdown** cells (with $\\LaTeX$ support). Answers that will be written in commented code blocks will not be checked.\n",
    "\n",
    "## In this exercise you will perform the following:\n",
    "1. Practice OOP in python.\n",
    "2. Implement two impurity measures: Gini and Entropy.\n",
    "3. Construct a decision tree algorithm.\n",
    "4. Prune the tree to achieve better results.\n",
    "5. Visualize your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I have read and understood the instructions: 205634272, 322698010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ed9fe7b1026e33cb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make matplotlib figures appear inline in the notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c6ac605270c2b091",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Warmup - OOP in python\n",
    "\n",
    "Our desicion tree will be implemented using a dedicated python class. Python classes are very similar to classes in Java.\n",
    "\n",
    "\n",
    "You can use the following [site](https://jeffknupp.com/blog/2014/06/18/improve-your-python-python-classes-and-object-oriented-programming/) to learn about classes in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.children = []\n",
    "\n",
    "    def add_child(self, node):\n",
    "        self.children.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Node at 0x7f839899a460>, <__main__.Node at 0x7f839899a790>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = Node(5)\n",
    "p = Node(6)\n",
    "q = Node(7)\n",
    "n.add_child(p)\n",
    "n.add_child(q)\n",
    "n.children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2f1ceb251c649b62",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "For the following exercise, we will use a dataset containing mushroom data `agaricus-lepiota.csv`. \n",
    "\n",
    "This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family. Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous\n",
    "one (=there are only two classes **edible** and **poisonous**). \n",
    "    \n",
    "The dataset contains 8124 observations with 22 features:\n",
    "1. cap-shape: bell=b,conical=c,convex=x,flat=f,knobbed=k,sunken=s\n",
    "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "4. bruises: bruises=t,no=f\n",
    "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
    "6. gill-attachment: attached=a,descending=d,free=f,notched=n\n",
    "7. gill-spacing: close=c,crowded=w,distant=d\n",
    "8. gill-size: broad=b,narrow=n\n",
    "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g,green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "10. stalk-shape: enlarging=e,tapering=t\n",
    "11. stalk-root: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r\n",
    "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "16. veil-type: partial=p,universal=u\n",
    "17. veil-color: brown=n,orange=o,white=w,yellow=y\n",
    "18. ring-number: none=n,one=o,two=t\n",
    "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n",
    "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n",
    "21. population: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n",
    "22. habitat: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d\n",
    "\n",
    "First, we will read and explore the data using pandas and the `.read_csv` method. Pandas is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d79cb4542926ad3f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('agaricus-lepiota.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of the Decision Tree algorithm is that almost no preprocessing is required. However, finding missing values is always required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cap-shape                   False\n",
       "cap-surface                 False\n",
       "cap-color                   False\n",
       "bruises                     False\n",
       "odor                        False\n",
       "gill-attachment             False\n",
       "gill-spacing                False\n",
       "gill-size                   False\n",
       "gill-color                  False\n",
       "stalk-shape                 False\n",
       "stalk-surface-above-ring    False\n",
       "stalk-surface-below-ring    False\n",
       "stalk-color-above-ring      False\n",
       "stalk-color-below-ring      False\n",
       "veil-type                   False\n",
       "veil-color                  False\n",
       "ring-number                 False\n",
       "ring-type                   False\n",
       "spore-print-color           False\n",
       "population                  False\n",
       "habitat                     False\n",
       "class                       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: Find columns with missing values and remove them from the data.#\n",
    "#############################################################################\n",
    "# We have none but just so we can use this code for other applications\n",
    "data.dropna(axis='columns',inplace=True)\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the dataset to `Training` and `Testing` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape:  (6093, 22)\n",
      "Testing dataset shape:  (2031, 22)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Making sure the last column will hold the labels\n",
    "X, y = data.drop('class', axis=1), data['class']\n",
    "X = np.column_stack([X,y])\n",
    "# split dataset using random_state to get the same split each time\n",
    "X_train, X_test = train_test_split(X, random_state=99)\n",
    "\n",
    "print(\"Training dataset shape: \", X_train.shape)\n",
    "print(\"Testing dataset shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p' 'e' 'e' ... 'e' 'p' 'p']\n",
      "['e' 'p']\n",
      "[4182 3942]\n",
      "[0.51477105 0.48522895]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the data\n",
    "l = X[:,-1]\n",
    "print(l)\n",
    "u, cnt = np.unique(l,return_counts=True)\n",
    "print(u)\n",
    "print(cnt)\n",
    "p=np.array(cnt)/len(l)\n",
    "print(p)\n",
    "np.sum(p*(1-p))\n",
    "len(p.shape)\n",
    "np.concatenate((np.array([0,1]),np.array([2,3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fd7b0191f3f1e897",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Impurity Measures\n",
    "\n",
    "Impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. Implement the functions `calc_gini` and `calc_entropy`. You are encouraged to test your implementation (10 points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have provided two methods below, both work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(data):\n",
    "    \"\"\"\n",
    "    Calculate gini impurity measure of a dataset.\n",
    " \n",
    "    Input:\n",
    "    - data: any dataset where the last column holds the labels.\n",
    " \n",
    "    Returns the gini impurity.    \n",
    "    \"\"\"\n",
    "    gini = 0.0\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    if len(data.shape) == 1: labels = data # allow passing labels as numpy array, mostly for testing\n",
    "    else: labels = data[:,-1] # otherwise, if it is a 2d array, then take the last column\n",
    "    n_obs = len(labels) # total number of observations\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True) # count frequencies of unique labels\n",
    "    probs = np.array(counts)/n_obs # empirical probabilities (normalized frequencies) of the labels\n",
    "    gini = np.sum( probs*(1-probs) ) # compute gini as p1*(1-p1)+p2*(1-p2)+...\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(data):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a dataset.\n",
    "\n",
    "    Input:\n",
    "    - data: any dataset where the last column holds the labels.\n",
    "\n",
    "    Returns the entropy of the dataset.    \n",
    "    \"\"\"\n",
    "    entropy = 0.0\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "\n",
    "    if len(data.shape) == 1: labels = data # same as in calc_gini: purely for testing\n",
    "    else: labels = data[:,-1] # if it is indeed a 2d array, then take the last column\n",
    "\n",
    "    # same as before: compute empirical probabilities of each class:\n",
    "    n_obs = len(labels) # total number of observations\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True) # count frequencies of unique labels\n",
    "    probs = np.array(counts)/n_obs # empirical probabilities (normalized frequencies) of the labels\n",
    "    \n",
    "    # now just use the entropy formula:\n",
    "    \n",
    "    entropy = np.sum( -probs*np.log2(probs) )\n",
    "    \n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Gini------------------\n",
      "Pure class:  0.0\n",
      "50/50 mix of 2 classes:  0.5\n",
      "10/90 mix of 2 classes:  0.18\n",
      "Equal mix of 3 classes:  0.6666666666666667\n",
      "Dataset X:  0.4995636322379775\n",
      "\n",
      "---------------Entropy---------------\n",
      "Pure class:  0.0\n",
      "50/50 mix of 2 classes:  1.0\n",
      "10/90 mix of 2 classes:  0.4689955935892812\n",
      "Equal mix of 3 classes:  1.584962500721156\n",
      "Dataset X:  0.9993703627906085\n"
     ]
    }
   ],
   "source": [
    "##### Your Tests Here #####\n",
    "#calc_gini(X), calc_entropy(X)\n",
    "\n",
    "print(\"---------------Gini------------------\")\n",
    "print(\"Pure class: \",calc_gini(np.ones(20)))\n",
    "print(\"50/50 mix of 2 classes: \",calc_gini(np.concatenate((np.ones(20),np.zeros(20)))))\n",
    "print(\"10/90 mix of 2 classes: \",calc_gini(np.concatenate((np.ones(10),np.zeros(90)))))\n",
    "print(\"Equal mix of 3 classes: \",calc_gini(np.concatenate((np.ones(20),np.zeros(20),np.ones(20)+1))))\n",
    "print(\"Dataset X: \",calc_gini(X))\n",
    "\n",
    "print(\"\\n---------------Entropy---------------\")\n",
    "print(\"Pure class: \",calc_entropy(np.ones(20)))\n",
    "print(\"50/50 mix of 2 classes: \",calc_entropy(np.concatenate((np.ones(20),np.zeros(20)))))\n",
    "print(\"10/90 mix of 2 classes: \",calc_entropy(np.concatenate((np.ones(10),np.zeros(90)))))\n",
    "print(\"Equal mix of 3 classes: \",calc_entropy(np.concatenate((np.ones(20),np.zeros(20),np.ones(20)+1))))\n",
    "print(\"Dataset X: \",calc_entropy(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(data):\n",
    "    \"\"\"\n",
    "    Calculate gini impurity measure of a dataset.\n",
    " \n",
    "    Input:\n",
    "    - data: any dataset where the last column holds the labels.\n",
    " \n",
    "    Returns the gini impurity.    \n",
    "    \"\"\"\n",
    "    gini = 0.0\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    gini = np.power(np.unique(data[:,-1], return_counts=True)[1] / len(data), 2)    \n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return 1.0 - np.sum(gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(data):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a dataset.\n",
    "\n",
    "    Input:\n",
    "    - data: any dataset where the last column holds the labels.\n",
    "\n",
    "    Returns the entropy of the dataset.    \n",
    "    \"\"\"\n",
    "    entropy = 0.0\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    probabilities = np.unique(data[:,-1], return_counts=True)[1] / len(data)\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return -np.sum(probabilities * np.log2(probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini,entropy\n",
      "Equal distributions:\n",
      "0.0 -0.0\n",
      "Unequal distributions:\n",
      "0.8999999999999999 3.321928094887362\n",
      "Dataset:\n",
      "0.4995636322379775 0.9993703627906085\n"
     ]
    }
   ],
   "source": [
    "##### Your Tests Here #####\n",
    "equal_distribution = np.ones(100).reshape(10,10)\n",
    "unequal_distribution = np.arange(100).reshape(10,10)\n",
    "\n",
    "print(\"Gini, Entropy\")\n",
    "print(\"Equal distributions:\")\n",
    "print(calc_gini(equal_distribution), calc_entropy(equal_distribution))\n",
    "\n",
    "print(\"Unequal distributions:\")\n",
    "print(calc_gini(unequal_distribution), calc_entropy(unequal_distribution))\n",
    "\n",
    "print(\"Dataset:\")\n",
    "print(calc_gini(X), calc_entropy(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goodness of Split\n",
    "\n",
    "Given a feature the Goodnees of Split measures the reduction in the impurity if we split the data according to the feature.\n",
    "$$\n",
    "\\Delta\\varphi(S, A) = \\varphi(S) - \\sum_{v\\in Values(A)} \\frac{|S_v|}{|S|}\\varphi(S_v)\n",
    "$$\n",
    "\n",
    "In our implementation the goodness_of_split function will return either the Goodness of Split or the Gain Ratio as learned in class. You'll control the return value with the `gain_ratio` parameter. If this parameter will set to False (the default value) it will return the regular Goodness of Split. If it will set to True it will return the Gain Ratio.\n",
    "$$\n",
    "GainRatio(S,A)=\\frac{InformationGain(S,A)}{SplitInformation(S,A)}\n",
    "$$\n",
    "Where:\n",
    "$$\n",
    "InformationGain(S,A)=Goodness\\ of\\ Split\\ calculated\\ with\\ Entropy\\ as\\ the\\ Impurity\\ function \\\\\n",
    "SplitInformation(S,A)=- \\sum_{a\\in A} \\frac{|S_a|}{|S|}\\log\\frac{|S_a|}{|S|}\n",
    "$$\n",
    "NOTE: you can add more parameters to the function and you can also add more returning variables (The given parameters and the given returning variable should not be touch). (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodness_of_split(data, feature, impurity_func, gain_ratio=False):\n",
    "    \"\"\"\n",
    "    Calculate the goodness of split of a dataset given a feature and impurity function.\n",
    "\n",
    "    Input:\n",
    "    - data: any dataset where the last column holds the labels.\n",
    "    - feature: the feature index.\n",
    "    - impurity func: a function that calculates the impurity.\n",
    "    - gain_ratio: goodness of split or gain ratio flag.\n",
    "\n",
    "    Returns the goodness of split (or the Gain Ration).  \n",
    "    \"\"\"\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    \n",
    "    n_obs = data.shape[0] # number of observations\n",
    "    var = data[:,feature] # variable to split on (here we just extract the actual array of values given the index)  \n",
    "    unique_vals, counts = np.unique(var, return_counts = True) # values available in the feature, with their counts\n",
    "    val_weights = np.array(counts) / n_obs # weights (probabilities) of different uniqe values in the specified feature\n",
    "    \n",
    "    goodness = impurity_func(data) # the first term; we will subtract the weighted impurities of the leaves below:\n",
    "    \n",
    "    # since below we are going to build a split anyway, shy don't we save an return it just in case;\n",
    "    # the caller will just discard it if it is not good enough...\n",
    "    split = {} \n",
    "    \n",
    "    for u_val, weight in zip(unique_vals, val_weights):\n",
    "        # get the subset of data where all values of the feature are equal to 'val' (i.e. a component of the split)\n",
    "        data_leaf = data[ var==u_val,: ]\n",
    "        leaf_impurity = impurity_func( data_leaf) \n",
    "        goodness -= weight*leaf_impurity\n",
    "        split[u_val] = data_leaf\n",
    "    \n",
    "    if gain_ratio:\n",
    "        # ok, now we need to calculate the split in information:\n",
    "        split_info = np.sum( - val_weights * np.log2(val_weights) )\n",
    "        # ... and normalize the entropy gain to it:\n",
    "        goodness /= split_info\n",
    "    \n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return goodness, split    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cell\n",
    "[goodness_of_split(X_train, f, calc_gini)[0] for f in range(X_train.shape[1]-1)]\n",
    "np.argmax([0,1,1,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Decision Tree\n",
    "\n",
    "Use a Python class to construct the decision tree. Your class should support the following functionality:\n",
    "\n",
    "1. Initiating a node for a decision tree. You will need to use several class methods and class attributes and you are free to use them as you see fit. We recommend that every node will hold the feature and value used for the split and its children.\n",
    "2. Your code should support both Gini and Entropy as impurity measures. \n",
    "3. The provided data includes categorical data. In this exercise, when splitting a node create the number of children needed according to the attribute unique values.\n",
    "\n",
    "Complete the class `DecisionNode`. The structure of this class is entirely up to you. \n",
    "\n",
    "Complete the function `build_tree`. This function should get the training dataset and the impurity as inputs, initiate a root for the decision tree and construct the tree according to the procedure you learned in class. (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    \"\"\"\n",
    "    This class will hold everything you require to construct a decision tree.\n",
    "    The structure of this class is up to you. However, you need to support basic \n",
    "    functionality as described above. It is highly recommended that you \n",
    "    first read and understand the entire exercise before diving into this class.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature, value=None, pred = None, counts = None):\n",
    "        self.feature = feature # column index of criteria being tested\n",
    "        self.children = []\n",
    "        self.split_value = value # the value of the *parent node's* feature split which brings us to this node\n",
    "        self.pred = pred # what do we predict for this node? Can be (but doesn't have to be) None for non-leaf nodes.\n",
    "        self.counts = counts # counts for each of the examples in the node\n",
    "        \n",
    "    def add_child(self, node):\n",
    "        self.children.append(node)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"(\"+(\"<None>\" if self.split_value is None else str(self.split_value) )+ \\\n",
    "                  \": \" + str(self.pred)+ (\" [LEAF]\" if len(self.children)==0 else (\" [Feature: \"+str(self.feature)+\", \"+ str(len(self.children))+ \" children]\"))+\")\" \n",
    "    \n",
    "    def __repr__(self): return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data, impurity, gain_ratio=False, min_samples_split=1, max_depth=1000):\n",
    "    \"\"\"\n",
    "    Build a tree using the given impurity measure and training dataset. \n",
    "    You are required to fully grow the tree until all leaves are pure. \n",
    "\n",
    "    Input:\n",
    "    - data: the training dataset.\n",
    "    - impurity: the chosen impurity measure. Notice that you can send a function\n",
    "                as an argument in python.\n",
    "    - gain_ratio: goodness of split or gain ratio flag\n",
    "    - min_samples_split: the minimum number of samples required to split an internal node\n",
    "    - max_depth: the allowable depth of the tree\n",
    "\n",
    "    Output: the root node of the tree.\n",
    "    \"\"\"\n",
    "    root = None\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    \n",
    "    # label counts for the current node\n",
    "    cnt_tuple = (unique_labels, counts) = np.unique(data[:,-1], return_counts = True)\n",
    "    node_pred = unique_labels[ np.argmax(counts) ] # what should we predict for this node\n",
    "    root = DecisionNode(None, pred=node_pred, counts=cnt_tuple) # set feature to None for now, as this node might end up being a leaf!\n",
    "    \n",
    "    if max_depth < 1: return root   # reached maximum depth, can't split anymore \n",
    "    if data.shape[0] < min_samples_split: return root # the node is too small, can't split anymore\n",
    "    if len(unique_labels) == 1: return root # the node is pure, nothing to split (we would get it from the gain too, but why bother...)!!\n",
    "\n",
    "    # OK, looks like we should try further splitting, let's do it:\n",
    "    best_gain = 0\n",
    "    best_feature = None\n",
    "    best_split = None\n",
    "    for feature in range(data.shape[1]-1): # try every feature (the last column is the outcome!)\n",
    "        gain, split = goodness_of_split(data, feature, impurity, gain_ratio)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_feature = feature\n",
    "            best_split = split\n",
    "    \n",
    "    if best_gain <= 1e-16: return root # no split results in any gain, give up...\n",
    "\n",
    "    # save the feature the current node has to be split on for the best result:\n",
    "    root.feature = best_feature\n",
    "\n",
    "    # let us now recursively split the children and save them.\n",
    "    # Note that if further split of a child is impossible, our build_tree function will still return \n",
    "    # that child as a node (with no children of course and with feature set to None)\n",
    "    for (value, data_slice) in best_split.items():\n",
    "        child_node = build_tree(data_slice, impurity, gain_ratio, min_samples_split, max_depth-1)\n",
    "        child_node.split_value = value\n",
    "        root.add_child(child_node)\n",
    "      \n",
    "    \n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python supports passing a function as an argument to another function.\n",
    "tree_gini = build_tree(data=X_train, impurity=calc_gini) # gini and goodness of split\n",
    "tree_entropy = build_tree(data=X_train, impurity=calc_entropy) # entropy and goodness of split\n",
    "tree_entropy_gain_ratio = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True) # entropy and gain ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree evaluation\n",
    "\n",
    "Complete the functions `predict` and `calc_accuracy`. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, instance):\n",
    "    \"\"\"\n",
    "    Predict a given instance using the decision tree\n",
    " \n",
    "    Input:\n",
    "    - root: the root of the decision tree.\n",
    "    - instance: an row vector from the dataset. Note that the last element \n",
    "                of this vector is the label of the instance.\n",
    " \n",
    "    Output: the prediction of the instance.\n",
    "    \"\"\"\n",
    "    pred = None\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    \n",
    "    f = node.feature\n",
    "    if f is None:\n",
    "        # we are at the leaf node, there are no more splits. Just predict\n",
    "        # according to what this node says:\n",
    "        return node.pred\n",
    "    \n",
    "    # the node prescribes to take a split on feature f. Let us get the value of that\n",
    "    # feature in the instance we are working with:\n",
    "    \n",
    "    val = instance[f]\n",
    "    \n",
    "    # now let us find the child node that corresponds to that value:\n",
    "    child = None\n",
    "    for ch in node.children:\n",
    "        if ch.split_value == val:\n",
    "            # gotcha!\n",
    "            child = ch\n",
    "            break\n",
    "    if child is None:\n",
    "        # oops, we did bot have any examples for this combination of feature values\n",
    "        # in the training set. Let us predict using the current node we were able to descend to:\n",
    "        return node.pred\n",
    "        #raise RuntimeError(\"Feature \"+ str(f)+\": instance value is \"+str(val)+\", not found in the tree! [Node=\"+str(node)+\"]\")\n",
    "    \n",
    "    # use the child node for prediction:\n",
    "    pred = predict(child, instance)\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x' 's' 'y' 't' 'l' 'f' 'c' 'b' 'w' 'e' 's' 's' 'w' 'w' 'p' 'w' 'o' 'p'\n",
      " 'n' 'n' 'g' 'e']  -->  e\n",
      "['k' 'y' 'e' 'f' 'y' 'f' 'c' 'n' 'b' 't' 's' 'k' 'p' 'w' 'p' 'w' 'o' 'e'\n",
      " 'w' 'v' 'l' 'e']  -->  e\n",
      "['f' 'y' 'n' 'f' 's' 'f' 'c' 'n' 'b' 't' 's' 'k' 'w' 'p' 'p' 'w' 'o' 'e'\n",
      " 'w' 'v' 'p' 'p']  -->  p\n",
      "['f' 'y' 'n' 't' 'a' 'f' 'c' 'b' 'n' 'e' 's' 'y' 'w' 'w' 'p' 'w' 'o' 'p'\n",
      " 'k' 's' 'p' 'e']  -->  e\n",
      "['x' 's' 'n' 'f' 'n' 'f' 'w' 'b' 'p' 't' 's' 's' 'w' 'w' 'p' 'w' 'o' 'e'\n",
      " 'n' 'a' 'g' 'e']  -->  e\n",
      "['f' 'f' 'y' 'f' 'f' 'f' 'c' 'b' 'p' 'e' 'k' 'k' 'p' 'n' 'p' 'w' 'o' 'l'\n",
      " 'h' 'v' 'p' 'p']  -->  p\n",
      "['k' 's' 'n' 'f' 'y' 'f' 'c' 'n' 'b' 't' 's' 's' 'p' 'w' 'p' 'w' 'o' 'e'\n",
      " 'w' 'v' 'l' 'p']  -->  p\n",
      "['x' 'f' 'w' 'f' 'n' 'f' 'w' 'b' 'p' 'e' 's' 'k' 'w' 'w' 'p' 'w' 't' 'p'\n",
      " 'w' 'n' 'g' 'e']  -->  e\n",
      "['k' 'y' 'n' 'f' 'y' 'f' 'c' 'n' 'b' 't' 's' 's' 'w' 'w' 'p' 'w' 'o' 'e'\n",
      " 'w' 'v' 'd' 'p']  -->  p\n",
      "['f' 's' 'e' 'f' 'f' 'f' 'c' 'n' 'b' 't' 'k' 'k' 'w' 'w' 'p' 'w' 'o' 'e'\n",
      " 'w' 'v' 'p' 'e']  -->  e\n"
     ]
    }
   ],
   "source": [
    "# A quick test:\n",
    "for i in range(10):\n",
    "    print(X_train[i,:],\" --> \",\n",
    "        predict(tree_entropy_gain_ratio, X_train[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(node, dataset):\n",
    "    \"\"\"\n",
    "    Predict a given dataset using the decision tree\n",
    " \n",
    "    Input:\n",
    "    - node: a node in the decision tree.\n",
    "    - dataset: the dataset on which the accuracy is evaluated\n",
    " \n",
    "    Output: the accuracy of the decision tree on the given dataset (%).\n",
    "    \"\"\"\n",
    "    accuracy = 0\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    correct = 0\n",
    "    for row in range(dataset.shape[0]):\n",
    "        instance = dataset[row, :]\n",
    "        truth = instance[-1] # the actual, correct label\n",
    "        pred = predict(node, instance)\n",
    "        if pred == truth: correct += 1\n",
    "    \n",
    "    accuracy = correct*100/dataset.shape[0]\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building the three trees using the training set, you should calculate the accuracy on the test set. For each tree print the training and test accuracy. Select the tree that gave you the best test accuracy. For the rest of the exercise, use that tree (when you asked to build another tree use the same impurity function and same gain_ratio flag). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Accuracies of the trees on the test set: ---------\n",
      "Gini:  77.5972427375677\n",
      "Entropy:  77.30182176267849\n",
      "Entropy with gain ratio:  78.58197932053176\n"
     ]
    }
   ],
   "source": [
    "#### Your code here ####\n",
    "print(\"---- Accuracies of the trees on the test set: ---------\")\n",
    "print(\"Gini: \",calc_accuracy(tree_gini, X_test))\n",
    "print(\"Entropy: \",calc_accuracy(tree_entropy, X_test))\n",
    "print(\"Entropy with gain ratio: \",calc_accuracy(tree_entropy_gain_ratio, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth pruning\n",
    "\n",
    "(15 points)\n",
    "\n",
    "Consider the following max_depth values: [1, 2, 3, 4, 5, 6, 7, 8]. For each value, construct a tree and prune it according to the max_depth value = don't let the tree to grow beyond this depth. Next, calculate the training and testing accuracy.<br>\n",
    "On a single plot, draw the training and testing accuracy as a function of the max_depth. Mark the best result on the graph with red circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your code here ####\n",
    "\n",
    "max_depths = np.array(range(1,9))\n",
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "for md in max_depths: \n",
    "    pruned_tree = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, max_depth= md) # entropy with gain ratio\n",
    "    accuracies_train.append(calc_accuracy(pruned_tree, X_train))\n",
    "    accuracies_test.append(calc_accuracy(pruned_tree, X_test))\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAH3CAYAAAD311i1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hVVfr28e9KI50Q0qgJhF6VBARRQESwYEERFQuoCIjd0bGNjs7vdcau2AYUFAdRwTIWFLAhDAJCEKSDBEJNCD2QepKz3j92iAEJBMjJSbk/13Wu5Oyzz95PIJA7a639bGOtRURERES8w8fbBYiIiIjUZgpjIiIiIl6kMCYiIiLiRQpjIiIiIl6kMCYiIiLiRQpjIiIiIl6kMCZSyxljhhtjbKnHQWPMb8aYO40xfl6qKc0YM8kL5/3JGDPPC+dNKP6zH+7Bc1xhjLn/GNv7FJ+7n6fOLSLH55X/aEWkSroa2AaEF3/+GhADPOGFWgYBWV44b012BdAPeMnbhYjIkRTGROSwZdbaDcWff2uMaQHcSxlhzBjjDxRaD3SOttYurehjiohUVZqmFJGyLAbCjDExpabRxhhjnjPG7ADygQhjzJPGmD8FMmPMJGNMWqnnh48xyhjzD2NMujFmvzHmK2NM46Pee8Q0Zamp1O7GmCnGmCxjzA5jzKvGmMCj3tvcGPONMSbHGJNpjHnRGDOy+P0J5fnCjTGXG2NWGmPyjTFrjTFDSr02uPhYnY/xvp+MMQtOcOxgY8ybxpg9xphDxpgvgcZl7NvbGPND8dRxtjFmljGmwzHOOe8ENU8ChgGNSk1Hpx11umBjzOvGmN3GmF3GmPeNMREn+rMSkdOnMCYiZWkGFAGHSm17DGgFjMSZSsw7heM+ArQAbgHuAXoAU8r53slAKnAl8G/gjuLjAWCMCQC+AzoDY4DhxV/HYydRXwvgVeDF4vNsAD4yxpxX/PrnwA5gVOk3GWNaA72B8Sc4/nhgBM504ZXAOuCDo3cyxlwC/IDz538DMBQIA/5njGlykjX/H/ANsAvnz7sHzt9faWMBW3yefwBXFW8TEQ/TNKWIHOZbvGA/DBiC80P9K2ttjjHm8D47gUGlpyZLvVZem621Q0u9Pxp43hjT0Fq74wTv/cBa+/fiz783xpwFXAcc3jYcaA6cZa1dVHz8GcAyoGk564sFelhrFxa/fyawCiegnGutLTTGvA3cZ4x50FqbXfy+UcB+YGpZBy4ObEOBx6y1zxRv/tYYEwqMPmr3scAca+3lpd4/G9gI/AVnCrm8NacaY3YBBYf3OYa51tq7StXUGhhhjBnuialoEfmDRsZE5LC1gAvYC7yJM1p1y1H7fF4BP5i/Pur5iuKP5QlLx3pv6fd1B7YcDmIAxfV+ehL1bS0dWKy1RcDHQDdjzOH/M98CgnGCIMVTpcOA/1hrc49z7LNw/t+ddtT2j0o/Mca0BBKBKcYYv8MPIAdYAPQ6hZpP5Fh/tnVwgp6IeJDCmIgcNgjoCrQBQqy1N1lr9x61T3oFnOfoY+YXfww8esdyvrdOqecNgMxjvG9n+Uorc9+dQAAQDVA8gvcFf4xmXQ1EcuIpygZlnOPo5zHFHyfiBOTSj4FA/ZOtuRxO5+9FRE6DpilF5LCVpa6mLMuxRsXywFmvZa0tKLX96MBQGdKBdsfYfjKjO8faNxYowFlzddibwA/GmCScKcr/WWtXl6O+w8fbeJxz7in++Ajw/TGOU3DU8/LWLCJVkEbGROR0bS7+WHKVX/FVeGd7oZaFQFNjTLdStRicxejl1cQY073U+31xRr4WWWvdh7dba38E1uAsxO8JjCvHsX8B3Dhr8kq79qjn64A0oL21NuUYj+WnUHM+EFSOGkWkkmlkTERO1wzgAPC2MebvONOGf+XIqzAryyTgIeAzY8xjOKNCI4B6xa+7y3hfaTuBqcVfyy7gdpwrSG8/xr7jcBba76Yc69KsteuMMR8A/yhey7UYuAC4+Kj9rDHmDuCL4itEpxWfIxYn5G6x1pZu3lqemlcDkcaY24EUIM9auwIR8TqNjInIabHW7sdZx+TGCQ3/wuneP9sLtRQA/YHlOEHpPWAr8EbxLgfKcZgNwF3AA8BnQEvgOmvtsb6ej4s/TrLW5h/j9WMZhbMW7AHgvzhr9IYevZO19huchfohwARgFvAcEIeziP9ka56Ac6HAP4FFwFflrFdEPMzoimURqemMMdOBttbaxAo+7m04i/ZblWO9nUcYY34C/Ky153jj/CJy+jRNKSI1inFuhn0I+B2nZ9rVwCUce5rxVM/RDqf1xFM47T68EsREpGZQGBORmiYfuA+n/5gvzmL4EdbaiRV4jjdx1m7NB+6swOOKSC2kaUoRERERL9ICfhEREREvUhgTERER8aJqu2YsKirKJiQkeLsMERERkRNasmTJbmvtMW9PVm3DWEJCAikpKd4uQ0REROSEjDGby3pN05QiIiIiXqQwJiIiIuJFCmMiIiIiXqQwJiIiIuJFCmMiIiIiXlRtr6Y8kaysLDIzM3G5XN4uRaoYf39/YmJiCA8P93YpIiIiNTOMZWVlsXPnTho1akRQUBDGGG+XJFWEtZbc3Fy2b98OoEAmIiJeVyOnKTMzM2nUqBHBwcEKYnIEYwzBwcE0atSIzMxMb5cjIiJSM8OYy+UiKCjI22VIFRYUFKQpbBERqRJqZBgDNCImx6XvDxERqSpqbBgTERERqQ4Uxmq44cOHM3DgQG+XISIiImWokVdTVkcnmjYbNmwYkyZNOunjjh07FmvtKVYlIiIinqYwVkWkp6eXfD59+nRuu+22I7YdfUGCy+XC39//hMetW7duxRUpIiIiFU7TlFVEXFxcySMiIuKIbXl5eURERPDhhx/St29fgoKCGD9+PHv27OG6666jcePGBAUF0b59e959990jjnv0NGWfPn0YM2YMjz76KFFRUcTExPDAAw/gdrsr9esVERERh8JYNfLII48wZswYVq9ezRVXXEFeXh5dunRh+vTprFq1invuuYdRo0bxww8/HPc4U6ZMwc/Pj/nz5/P666/zyiuvMHXq1Er6KkRERKS0WjNN+dRXq1i9I6tSz9muYTh/v7R9hR3vrrvuYvDgwUdse/DBB0s+HzlyJD/++CMffvgh559/ftl1tWvHP/7xDwBatWrF22+/zQ8//MB1111XYbWKiIhUB2m7s0mICvFqDRoZq0aSk5OPeF5UVMTTTz9Np06dqF+/PqGhoXz22Wds2bLluMfp1KnTEc8bNmyobvQiIlKrWGv5z4I0Lnh5Dv9dus2rtdSakbGKHKHylpCQI5P7Cy+8wIsvvsjYsWPp2LEjoaGhPProoycMVkcv/DfGaM2YiIjUGrkFRTz23xV8tnQ757eJoW+bWK/WU2vCWE00b948Lr30Um688UbASfnr168vuQBAREREjrRlTw6j3l/C2ows7uvXirv6tsDHx7t3ZdE0ZTXWqlUrfvjhB+bNm8fatWu588472bRpk7fLEhERqZJmr81k4Gv/Y/u+HN4Z3pV7+rX0ehADhbFq7W9/+xvdunXjoosuolevXoSEhHD99dd7uywREZEqxe22vPL9em55bzGN6gUz/a5zOa91jLfLKmGqa3f25ORkm5KScszX1qxZQ9u2bSu5Iqlu9H0iIlLzHchxcd+0Zfy4NpMrz2zE04M6EhTgW+l1GGOWWGuTj/Wa1oyJiIhIjbQmPYvR7y9hx/5c/u/y9tzQPf6Etx/0BoUxERERqXE+X7qdhz9bTt0gfz4a2YOk+HreLqlMCmMiIiJSYxQUuvnnN2uYND+Nbs0ieX3omcSEBXq7rONSGBMREZEaITMrjzFTfiVl8z5uPacZD1/UBn/fqn+tosKYiIiIVHuL0/YyZsqvHMor5NXrzuSyzg29XVK5KYyJiIhItWWtZdL8NJ7+eg1NIoN5/9azaB0X5u2yTorCmIiIiFRLOQWFPPLZCr5YtoN+bWN56ZrOhAf6n/iNVYzCmIiIiFQ7abuzGf3+EtbtPMgD/Vsxpo/3b2t0qhTGREREpFr5Yc1O7p26DF8fw6Sbu9G7VbS3SzotCmMiIiJSLRS5LWO/X8+rP26gfcNwxt2QRJPIYG+Xddqq/vWetYQx5riP4cOHn/Kxn3zySTp06FBxxYqIiFSy/TkF3DJpMa/+uIHBSY359Paza0QQA42MVRnp6ekln0+fPp3bbrvtiG1BQUHeKEtERMTrVu04wOj3l5BxII//d0UHrj+raZW8rdGp0shYFREXF1fyiIiI+NO2uXPnkpSURGBgIM2aNeOxxx6joKCg5P2fffYZnTp1IigoiMjISHr37s3OnTuZNGkSTz31FKtWrSoZZZs0aZKXvkoREZGT8+mSbVz55nxchZapo3pU2ftLng6NjFUDs2bN4vrrr2fs2LH06tWLLVu2MHr0aPLz83nhhRfIyMjg2muv5V//+hdXXXUVhw4dYuHChQBcc801rFy5kunTp/PTTz8BULduXS9+NSIiIidWUOjm/6avZvLCzXRvHslr13UhOqyOt8vyiNoTxmY8DBkrKveccR3homdO+zBPP/00Dz74IDfffDMAiYmJPPvss9xwww08//zz7NixA5fLxeDBg4mPjwc4Yo1YaGgofn5+xMXFnXYtIiIinpZxII8xU5bw65b9jOzVnL8OaI1fNbit0amqPWGsGluyZAmLFi3i2WefLdnmdrvJzc0lIyODzp07069fPzp06ED//v3p168fgwcPJjq6el/qKyIitc/CjXu484NfySko4o2hXbikUwNvl+RxtSeMVcAIlbe43W7+/ve/c/XVV//ptejoaHx9ffn2229ZuHAh3377LRMnTuSRRx5hzpw5dO7c2QsVi4iInBxrLRPnbeJfM9YSHxnMh7d1p2Vs9bqt0amqPWGsGuvSpQtr166lRYsWZe5jjKFHjx706NGDJ554gvbt2zN16lQ6d+5MQEAARUVFlVixiIhI+WXnF/LQp8uZvjydAe1jeeHqzoRVw9sanSqFsWrgiSeeYODAgcTHxzNkyBD8/PxYuXIlixYt4rnnnmPhwoV8//33DBgwgNjYWJYuXcrWrVtp164dAAkJCWzevJlff/2Vpk2bEhYWRp06NXMRpIiIVC+bdmczanIKGzIP8dcLW3N778Qad7XkidTc1XA1yIABA/j666+ZPXs23bp1o1u3bjzzzDM0bdoUcK6O/Pnnnxk4cCAtW7bkL3/5C48//jg33HADAFdddRUXX3wx559/PtHR0Xz44Yfe/HJEREQA+G71Ti57bR67Dubzn1vOYkyfFrUuiAEYa623azglycnJNiUl5ZivrVmzhrZt21ZyRVLd6PtERMQ7ityWl79bz+uzN9CpcV3evL4LjevVjG76ZTHGLLHWJh/rNU1TioiISKXZl13A3R8t5X+/7+bark148rL2BPr7erssr1IYExERkUqxcvsBRk1ewq6D+fzryo5c162pt0uqEhTGRERExOOmpWzlb5+vJCokgGmje3BGkwhvl1RlKIyJiIiIx+QXFvHUV6v54JctnJ1Yn9euO5P6obqivzSFMREREfGI9AO53P7+ryzbup9RvZvzYP+afVujU6UwJiIiIhVufupu7vpgKXmuIv59fRcu6ljzb2t0qhTGREREpMJYa3n7fxt5ZsZamkWFMP7GHrSICfV2WVWawpiIiIhUiEP5hTz0yXK+XpHORR3ieP7qzoTWUdQ4Ef0JiYiIyGlL3XWIUZOXsHHXIR65qA0jezWvld30T4XCmIiIiJyWmSszeODj3wjw8+H9W8/i7BZR3i6pWtElDWVITU3lvjFjiA0Px9fHh9jwcO4bM4bU1FSPnXP48OEYY0oeUVFRDBw4kLVr11bI8dPS0jDGUNZtpMrr0KFD3HXXXTRu3JigoCBat27Nyy+/fMQ+qampDBo0iOjoaMLDwxkyZAg7d+484bGzsrK4++67adiwIXXq1KFFixZMmzat5PUpU6bQpEkTIiMjuf/++4947/bt20lISCjXeURE5PQVuS3PzlzL6PeXkBgTyvS7zlEQOwUKY8cwY8YMunfqRNCECcw/eJB8a5l/8CBBEybQvVMnZsyY4bFz9+vXj/T0dNLT0/n222/Jzc1l0KBBHjvfqbj//vv5+uuvmTx5MmvWrOGxxx7j4YcfZvLkyQBkZ2fTv39/rLX88MMP/PzzzxQUFHDppZfidrvLPK7L5aJ///78/vvvTJs2jXXr1jFp0iSaNWsGwO7duxkxYgQvvPACs2bN4v3332f69Okl77/jjjt4/PHHiY2N9ewfgIiIsOdQPsPeWcS/f0rlum5NmTaqOw0jgrxdVvVkra2Wj6SkJFuW1atXl/naiWzYsMFGBQfb+WDtMR7zwUYFB9sNGzac8jnKMmzYMHvJJZccse2rr76ygM3JybHWWrtt2zZ7zTXX2IiICBsREWEvvvhiu379+pL9t2zZYi+77DJbr149GxQUZFu3bm0//PBDa621wBGP3r17n1Kd7du3t0888cQR23r16mXvuOMOa621s2bNssYYu3fv3pLX9+/fb40x9rvvvivzuOPHj7fNmjWz+fn5x3z9l19+sbGxsSXPhwwZYp977jlrrbWffPKJ7dOnj3W73eX+Ok7n+0REpDZbtmWf7fHP723Lx76xUxdt8XY51QKQYsvINBoZO8rrL77IbS4XPcp4vQcwwuXijaOm5Tzh4MGDTJ06lY4dOxIUFEROTg7nnXcegYGBzJkzhwULFtCgQQP69etHTk4OAGPGjCEnJ4fZs2ezatUqXnnlFSIinFtOLFq0CICZM2eSnp7OZ599BjhTf6Ghocd9TJkypaSuc845h6+++oqtW7cCMH/+fJYtW8aFF14IQH5+PsYYAgMDS94TGBiIj48P8+bNK/Pr/fzzz+nZsyd33XUXcXFxtGvXjieffBKXywVAy5YtycnJYenSpezdu5fFixfTqVMnDhw4wIMPPsj48eO1WFRExMM+WrSFq8ctwBjDJ6N7MKRrE2+XVO3VmgX8zy56lrV7T7z26rP3pvBr8Q//soxwuejy7lvsG5h93P3aRLbhoW4PnVSdM2fOJDTU6ceSnZ1NkyZN+OabbwD46KOPsNby7rvvloSO8ePHExMTw/Tp0xkyZAibN2/mqquuonPnzgAlU3wA0dHRANSvX5+4uLiS7ZdddhlnnXXWcesqPfX36quvMnr0aJo2bYqfn/Mt9NprrzFw4EAAunfvTmhoKA8++CDPPvssAA8//DBFRUWkp6eXeY6NGzfy448/MnToUL7++mvS0tK44447OHToEC+88AL16tXjvffe46abbiI3N5ebbrqJAQMGMGrUKEaMGMHu3bsZOnQo2dnZ3HPPPYwePbocf+IiIlIeea4invxyFR8t3sq5LaMYe+2ZRIYEeLusGqHWhLHyOpTrIv4E+zQt3s8TevXqxVtvvQXA3r17efPNN+nfvz+//PILS5YsYdOmTYSFhR3xnpycnJILCw6HkJkzZ3L++eczaNAgkpKSjnvOsLCwPx3zeF577TV+/vlnvvzyS+Lj45k7dy4PPPAACQkJXHjhhURHR/Pxxx9z++238+abb+Lj48N1111Hly5d8PX1LfO4brebmJgY3n77bXx9fUlKSmLPnj3cd999PP/88xhjGDRo0BFr6ObNm8fChQt58cUXad26Ne+99x7t27enU6dO9OzZk44dO5b76xIRkWPbvj+X299fwvJtB7jjvETuv6A1vj6aiagotSaMlXeE6pvQT9l88CCJx9lnCxAdFs67F75bIbWVFhwcTIsWLUqeJyUlUbduXd566y3cbjdnnHEGH3300Z/eFxkZCcCtt97KgAED+Oabb/j+++85++yzeeSRR3jyySfLPOeUKVMYNWrUcesaP348119/Pbm5uTzyyCN8/PHHXHrppQB06tSJZcuW8cILL5RMVfbv35/U1FR2796Nn58fERERxMXFHTFSd7QGDRrg7+9/RGBr27YtOTk57N69u2Rk77CCggJGjx7NhAkT2LhxIwUFBfTr1w+APn368NNPPymMiYicpp837OauD5dSUOhm/I1JDGgfd+I3yUmpNWGsvIbecAMTJ0zgn8eZqpzg78/QG2+slHqMMfj4+JCTk0OXLl348MMPiYqKKlkHdiyNGzdm5MiRjBw5kmeffZaxY8fy5JNPEhDgDCcXFRUdsf/JTFO6XC5cLtefRrh8fX2PeaVkVJRzifOPP/5IZmYml112WZnn6NmzJx988AFutxsfH2c54/r16wkODi45TmlPP/00ffv2pXv37ixbtozCwsKS1woKCv70dYqISPlZaxk3ZyPPz1pLYnQo425MIjFatzXyiLJW9lf1R029mrJfv342PT3dpqen29WrV9sxY8ZYY4ydPXu2zc7Otq1atbK9evWyP/30k924caOdM2eOvf/++0uuqLz77rvtjBkzbGpqql26dKnt06ePPf/886211rpcLhsUFGSfeuopm5GRYffv339Kdfbu3du2b9/ezp49227cuNG+++67NjAw0L766qsl+7zzzjt2/vz5dsOGDXby5Mk2MjLS3n///Uccp2/fvvbhhx8ueb5lyxYbFhZm77zzTrt27Vo7c+ZM26hRI/vAAw/8qYZVq1bZxMREm5WVZa21Nicnx0ZFRdl///vfdu7cuTYkJMQuXrz4uF+HrqYUETm2rNwCO/I/i238Q9PtmPeX2EN5Lm+XVO1xnKspKz1EAfcAK4FVwL3F254H1gLLgf8CESc6jqfCmLXWfvPNNzYqONg+7O9vN4AtALsB7MP+/jYqONh+8803p3X8sgwbNuyI1hNhYWG2a9eu9pNPPinZJyMjww4fPtxGR0fbgIAAm5CQYG+++Wa7a9cua621d955p23RooWtU6eOjYqKstdcc43dtm1byfvffvtt26RJE+vj43PKrS3S09Pt8OHDbcOGDW1gYKBt3bq1ff75549oK/HQQw/Z2NhY6+/vb1u2bGlffPHFP7WdiI+Pt8OGDTti24IFC2yPHj1sYGCgTUhIsI8//vifWl243W7bs2dP++WXXx6xfcaMGbZ58+a2fv369p///OcJvw6FMRGRP/t9Z5Y974XZtvkjX9u356aeVMsgKdvxwphxXq8cxpgOwEdAN6AAmAncDjQDfrTWFhpjni0esTvuIq/k5GRbVif5NWvW0LZt29OqNTU1lTdefpkPJk9m96FDRIWGMvTGG7njvvtITDzeijKpLiri+0REpCb5ZkU6D378G0EBvrx2XRd6JNb3dkk1hjFmibU2+VivVfaasbbAQmttDoAxZg4wyFr7XKl9FgKDK7muP0lMTOSl11/npddf93YpIiIiHlVY5Ob5WesYP3cjZzaN4M3ru9CgrrrpV5bKDmMrgaeNMfWBXOBi4OjhrVuAqcd6szFmJDASoGnTph4sU0REpHbYfSifuz5YyoKNe7ihe1MeH9iOOn5ltyGSilepYcxau6Z4GvI74BDwG1ByCZwx5rHi51PKeP9bwFvgTFN6vGAREZEabOmWfYyZ8it7swt44erODE5q7O2SaqVKvx2StXaitbaLtbYXsBf4HcAYMwwYCFxvK3Mhm4iISC1jrWXKL5u5ZvxCfH0Mn95+toKYF1V6nzFjTIy1NtMY0xS4EuhhjLkQeAjofXg92emy1uo+hVIm5X0Rqa3yXEU8/vlKPl6yjV6tohl7zRnU022NvMobTV8/LV4z5gLusNbuM8a8DtQBvisOUAuttad8Y0F/f39yc3MJDg6umIqlxsnNzcXf39/bZYiIVKqte3O4fcoSVm7P4u6+LbinXyvd1qgKqPQwZq099xjbWhxr31MVExPD9u3badSoEUFBQRohkxLWWnJzc9m+ffsRNz8XEanp5q7fxd0fLaXIbZlwUzL92un/wKqiRt4OKTw8HIAdO3bgOs5tjaR28vf3JzY2tuT7RESkJnO7Lf+ek8oL366jVUwY425MollUiLfLklJqZBgDJ5Dph62IiNRmWXku/jLtN75bvZPLOjfkmas6EhxQY3/0V1v6GxEREamB5q7fxSOfrSAjK48nBrbj5p4JWrZTRSmMiYiI1CAHcl08/fVqpqVsIzE6hGmjepAUX8/bZclxKIyJiIjUED+u3cmjn60k82Aeo3sncm+/lgT6q5t+VacwJiIiUs3tzyngqa9W89+l22kdG8b4G5Po3CTC22VJOSmMiYiIVGMzV2bwt89Xsj+ngLv7tuCOvi10b8lqRmFMRESkGtpzKJ8nvlzF18vTadcgnPdu6Ur7hnW9XZacAoUxERGRasRay/Tl6fz9y1UczHPxlwtaMbpPIv6+lX67aakgCmMiIiLVRObBPB7/fCWzVu2kc+O6PDe4O63jwrxdlpwmhTEREZEqzlrLf5du56mvVpPrKuLhi9ow4pxm+Gk0rEZQGBMREanCMg7k8eh/V/Dj2kyS4uvx3OBOJEaHerssqUAKYyIiIlWQtZZpKVv5f9PX4HK7eXxgO4afnYCvj7ro1zQKYyIiIlXMtn05PPLZCv73+27OahbJc4M7EV9fN/euqRTGREREqgi32zJl0Rae+WYNFvi/y9tz/Vnx+Gg0rEZTGBMREakCtuzJ4a+f/sbCjXs5p0UU/7qyI00ig71dllQChTEREREvcrstk+an8fysdfj5GJ65siPXdG2CMRoNqy0UxkRERLxk465D/PWT5aRs3sd5raP555UdaVA3yNtlSSVTGBMREalkRW7LhP9t5KXv1lPHz4cXr+7MlV0aaTSsllIYExERqUS/7zzIA58s57et+7mgXSxPX9GBmPBAb5clXqQwJiIiUglcRW7emruRsd//TkgdX1697kwu7dRAo2GiMCYiIuJpq3dk8eAnv7FqRxaXdGrAU5e1Jyq0jrfLkipCYUxERMRDCgrdvDF7A2/M3kBEsD/jbujChR0aeLssqWIUxkRERDxgxbYDPPjJb6zNOMigMxvxxMB21AsJ8HZZUgUpjImIiFSgPFcRr/7wO+PnbiQqNICJw5I5v22st8uSKkxhTEREpIL8umUff/1kORsyDzEkuTGPXdKOukH+3i5LqjiFMRERkdOUW1DES9+tY72oqHIAACAASURBVOK8TcSFB/LeLd3o3Sra22VJNaEwJiIichoWbdrLXz/5jbQ9OVx/VlMevqgNYYEaDZPyUxgTERE5Bdn5hTw/ax3vLUijcb0gPhhxFme3iPJ2WVINKYyJiIicpPkbdvPQZ8vZti+XYT0SeHBAa0Lq6EeqnBp954iIiJTTwTwX/5qxlg9+2UKzqBCmjepB14RIb5cl1ZzCmIiISDnMWb+LRz5dTkZWHiN7Nee+fq0ICvD1dllSAyiMiYiIHMeBHBf/7+vVfLxkGy1iQvn09rM5s2k9b5clNYjCmIiISBm+X72TR/+7gj3ZBdxxXiJ39W1JoL9Gw6RiKYyJiIgcZV92AU99tYrPl+2gTVwYE4d1pWPjut4uS2oohTEREZFSZqxI5/EvVrI/x8W9/Voypk8LAvx8vF2W1GAKYyIiIsDuQ/n8/YtVfL0inQ6Nwpl861m0bRDu7bKkFlAYExGRWs1ay5e/7eDJL1eRnV/EgwNaM6pXc/x8NRomlUNhTEREaq3MrDwe+3wl363eyRlNInh+cCdaxoZ5uyypZRTGRESk1rHW8umv2/nHV6vIL3Tz2MVtueWcZvj6GG+XJrWQwpiIiNQq6QdyefSzFcxet4uuCfV49qpONI8O9XZZUospjImISK1greWjxVv559drKHRbnry0HTf1SMBHo2HiZQpjIiJS423dm8Mjn61g3obd9Ghen2ev6kTT+sHeLksEUBgTEZEazO22vP/LZp6ZsRYD/L8rOjC0W1ONhkmVojAmIiI1UtrubB76dDm/bNrLuS2jeOaqTjSKCPJ2WSJ/ojAmIiI1SpHbMml+Gs/PWou/rw/PDe7E1UmNMUajYVI1KYyJiEiNsSHzEA99upwlm/dxfpsYnh7Ukbi6gd4uS+S4FMZERKTaKyxyM2HeJl76bj3BAb68cs0ZXH5GQ42GSbWgMCYiItXauoyD/PWT3/ht2wEubB/HP65oT0yYRsOk+lAYExGRaqfIbVmbkcXMlRmMm5NKeKA/bwztwsUd4zQaJtWOwpiIiFR5OQWFLNuyn8Vp+0jZvJelW/ZzKL8QgEs7N+TJS9tRP7SOl6sUOTUKYyIiUuVkZuWRsnkfi9P2smTzPlbtyKLIbTEGWseGccWZDemaEElSfD0a11PzVqneFMZERMSr3G5L6q5DJaNeKWn72LI3B4BAfx/OaBLB7b0TSU6ox5lN61E3yN/LFYtULIUxERGpVHmuIlZsP+CMeqXtI2XzPg7kugCICg0gKb4eN/WIJym+Hu0b1iXAz8fLFYt4lsKYiIh41N7sApZs/mPUa8W2AxQUuQFIjA7hwvZxJCfUIzkhkoT6wVqAL7WOwpiIiFQYay2b9+SUrPVanLaX1F3ZAPj7Gjo2qsvNPRNIiq9HUnw9LboXQWFMREROg6vIzaodWaSkOaNeKZv3svtQAQB1g/xJiq/HVUmNSY6PpFPjugT6+3q5YpGqR2FMRETKLSvPxa+b95UEr2Vb95PncqYcm0QG0atlNEkJ9eiaEEmL6FB8fDTlKHIiCmMiIlKm7ftzS0a9FqftZd3Og1gLvj6Gdg3Cua5bU5LjI0lOqEdsuLrei5wKhTEREQH+6GqfUnyFY0raXtIP5AEQEuBLl/h6XNShAckJ9TijSQQhdfQjRKQi6F+SiEgtdbyu9nHhgc4VjvHOVY5t4sLw81WLCRFPUBgTEaklytPV/vCUY6OIILWYEKkkCmMiIjXQ8bra1/FzutqP7t2c5IRIuqirvYhXKYyJiNQAx+tqXz8kgOSEetzYPZ7kBHW1F6lqFMZERKqh43W1b17c1f5wiwl1tRep2hTGRESquPJ0tR/eM4FkdbUXqZYUxkREvMTtthzML+RAjosDuc5jf25ByecHclxs3pNzRFf78EA/khMiubJLY7omqKu9SE2gMCYichqsteQUFDlBqlSoOlAqVB25/Y9tB/NcuG3Zxw7w8yEuPJBzW0aTrK72IjWWwpiICM4C+KyS0SlXyWjV/uJtWbku9ucUHGObi8LjJCpfH0PdIH8igvwJD/KnXnAAzaJCjthWN8ifiOAA6pZ87nzUiJdI7aAwJiI1RmGR+8jRp+LAdPTo1P6c4iBVavTq8P0VyxIe6EfdYH8igpzQ1LBuEHWLQ9PhYHX488PbI4IDCAnw1eJ5ETkuhTERqVLKs46qrOm/w93jyxIc4HvEaNThEarDwSn8qFB1eIQqLNAfX00NioiHKIyJSKXLLShizvpd/Lh2J+kH8o4IVFm5J1hH5etTPELlBKUGdQNp0yDsyBGqkhGrgJJQFR7or95aIlIlKYyJSKU4kOti9tpMZq7M4Kf1meS53NQN8ichKoR6wQEk1A85YjSq7hEjVH+spwr099G0n4jUKApjIuIxuw7m893qncxclcGC1N24iiyx4XW4OqkJF3aIo1uzSPx182kRqeUUxkSkQm3bl8OsVTuZtTKDxZv3Yi00jQzmlp7NGNAhjjMaR6g1g4hIKQpjInLaNmQeZObKDGat2smK7QcAaBMXxt19W3JhhzjaxIVpalFEpAyVHsaMMfcAtwEGeNta+4oxJhKYCiQAacAQa+2+yq5NRMrHWsvK7VnMXJXOzJUZJbfmObNpBI9c1IYB7eNIiArxcpUiItVDpYYxY0wHnCDWDSgAZhpjvi7e9oO19hljzMPAw8BDlVmbiBxfkduSkrbXmYJclcH2/bn4+hjOahbJsLMT6N8ujri6gd4uU0Sk2qnskbG2wEJrbQ6AMWYOMAi4HOhTvM97wE8ojIl4XUGhm/mpu5m1KoNvV+1kT3YBAX4+9GoZxb39WtKvbSz1QgK8XaaISLVW2WFsJfC0MaY+kAtcDKQAsdbadABrbboxJqaS6xKRYjkFhcxdv4uZKzP4YW0mB/MKCQnw5bw2MVzYIY4+rWMIraPlpiIiFaVS/0e11q4xxjwLfAccAn4Djt8yuxRjzEhgJEDTpk09UqNIbXQgx8UPa3cyc2UGc3/fRZ7LTb1gfy7qEMeFHeI4OzFK90kUEfGQSv/11lo7EZgIYIz5J7AN2GmMaVA8KtYAyCzjvW8BbwEkJycfp0e3iJxI5sE8pwfYygwWpO6h0G2JCw/kmuQmDOgQR7eESPzUA0xExOO8cTVljLU20xjTFLgS6AE0A4YBzxR//KKy6xKpDbbuzWHWqgxmrsxgyZZ9WAsJ9YMZcW5zBrSPpbN6gImIVDpvLPz4tHjNmAu4w1q7zxjzDDDNGHMrsAW42gt1idQ41lo2ZB5i5soMZq7KYNWOLADaNgjn3vNbcWGHOFrFhqoHmIiIF3ljmvLcY2zbA5xf2bWI1ETWWpZvO8DMVRnMWpnBxt1OD7Ck+Ho8erHTAyy+vnqAiYhUFbokSqQGKHJbFqftZebKDL5dlcGOA3n4+hh6NK/Pzec0o3+7WGLD1QNMRKQqUhgTqabyC4uYn7qHWSsz+G610wOsjp8P57aM5v7+renXNoaIYPUAExGp6hTGRKqR7PxC5hT3APtxbSaH8gsJreNH3+IeYL1bRROiHmAiItWK/tcWqeL25xTw/ZpMZq3KYO76XeQXuokMCeCSjg2cHmAt6lPHTz3ARESqK4UxkSooMyuPWat3MmtlBgs27qHIbWlQN5DrujVlQPs4uibUUw8wEZEaQmFMpIrYsqe4B9iqDH4t7gHWPCqEkb2ac2H7ODo1rqsWFCIiNZDCmIiXWGtZv/OPHmBr0p0eYO0bhnN/P6cHWIsY9QATEanpFMZEKpHbbVm+/QAzV2Ywa1UGm3ZnYwwkNa3H3y5py4D2cTSJDPZ2mSIiUokUxkQ8rLDIzaK0vcxamcG3q3eSfiAPPx9Dj8T6jDi3GRe0iyUmTD3ARERqK4UxEQ9ZsnkfUxdv4bvVO9mX46KOnw+9W0Xz4IDWnN8mlrrB/t4u0WtSU1N5/cUX+eD999l96BBRoaEMveEG7vzLX0hMTPR2eSIilUphTKQCWWuZvS6Tf/+UyuK0fYTV8aNv2xgubB9H79bRBAfon9yMGTO4afBgbnO5mO9yEQ9sPniQiRMm0P299/jPJ59w0UUXebtMEZFKY6y1J/cGYyKAscCFgAFmAfcW31+y0iQnJ9uUlJTKPKVImVxFbr76bQfj52xk3c6DNIoI4tZzmnFttyYKYKWkpqbSvVMnvszJoccxXl8AXBYczMLlyzVCJiI1ijFmibU2+VivncpPiX8DdYFbgTDgMWA8MPiUKxSppnIKCvlo0VYmztvE9v25tI4N46Uhnbm0c0P81QfsT15/8UVuc7mOGcQAegAjXC7eePllXnr99cosTUTEa8ocGTPGdLXWLj7G9l1AgrU2u/j5hcBH1toIj1Z6FI2MiTftzS5g0vw0/rMgjf05LrolRDK6T3POax2jVhRHsxayd8GeVGLb92V+dh7HG/NKBXqGh5Nx4EBlVSgi4nGnOjL2ozFmMvCotXZ/qe27gG7A7OLnXYu3idR4W/fmMOF/G5maspU8l5sL2sUyunciSfH1vF2a9+XshT2psDf1qI8bId/pobY7O4/4ExymKbD70CGPlysiUlUcL4x1AF4F1hpjHrTWTi7e/hQwwxizAggBWgLDPVqliJetSc9i3JxUpi9Px8fAFWc0YlTv5rSICfN2aZUrL+vIkLVnwx/BK3ffH/sZH6jbBOonQuOuUL8F1E8k6sVBbD6UfdyRsS1AVB1f+P17SOwLPpruFZGarcwwZq3dDFxujBkIjDXGjABGW2unGmOWA+cX7/qjtXZ1JdQqUqmstfyyaS/j5qTy07pdhAT4ckvPBG45pxkN6gZ5uzzPKcguDlqHR7c2Fn/c4Ew3lhbeyAlc7a5wPkYmOsGrXjz41fnToYfeeBMTJ0zgny5Xmaef4OvD0DOCYMpVEBEPScPhzBshNLqCv1ARkaqhXFdTGmMCcRbq3wu8AfzDWpvj4dqOS2vGxFPcbsu3q3cybk4qy7bup35IADf3TODG7gk1pzeYKw/2pf0RskpGulLh4I4j9w2NLQ5ZzZ2gFZnoBK96zSDg5O4WUO6rKX9dTGLBakh5FzbPAx9/aHcZJN8C8T1B6/JEpJo53pqxk2ptYYxpCbwGtAXuttZ+UTElnjyFMalo+YVFfL50O+PnbmTjrmyaRgZzW6/mXJ3UmEB/X2+Xd/KKXLBv81FruDY4I10HtgKl/u0H1/8jZB3+WD8RIptDnYqdij3cZ2yEy8UIl4umOFOTE/z9meDv/+c+Y7vWOaHstw8g7wBEtXJCWedrIUhr9USkejilMGaMqQM8BFwEBOL80vqUtXanMeZq4CXgN+CO4inNSqUwJhXlYJ6LD37Zwjs/b2JnVj7tG4YzunciF3WIw6+qt6dwFznB6nDIKh289m0GW/THvnXqlgpZpT82r/RQk5qayhsvv8wHkyf/0YH/xhu54777yu4vVpADq/4LKRNh+xLwC4QOV0HyrdCoi0bLRKRKO9Uw9hZOEHsdyAZuBrDWJhW/HoKzmH8E8Ly19umKL71sCmNyujIP5vHuz2m8v3AzB/MK6dmiPqN7J3JOi6iq1Z7C7XamDktfoVgSuNKgqOCPff1DnHB1eO1W6eAVXL/mBJYdy2DJu7D8Y3BlQ1wnZ7Ss49VQJ9Tb1YmI/MmphrE9wDBr7fTi5w2BrUALa+2mUvu1B96w1vap6MKPR2FMTlXa7mzGz93Ip79uw1Xk5uIODRjVuzmdGldqq7wjWQuHdpbRGmITFOb+sa9foDN9GNn8yEXz9ROd9V01JXCVR14WrJgGi9+BzFUQEAadhjjBLK6Dt6sTESlxqn3G9gHtgOnFz9vh3P7oiE6M1tpVQJ/TL1PEs5Zv28+4OanMWJmBv68Pg5MaM/Lc5iREhVROAdY6vbiOWDRfqk1EQaneWj7+UC/BCVmJfY8MXuGN1O7hsMBw6DrCmarcughS3oGl7ztTmU3OckJZuyvAP9DblYqIlOl4I2NDgUnAeiAX6AyMtdY+WGnVHYdGxqQ8rLXM27CbcXNS+XnDHsIC/bixezzDeyYQE+bhH9AZK2Dt18XTihuc4JVX6ncZ4wsRTY8a3SqeYqzbBHx1T8tTkrMXln3gBLO9qc56uDOuh6SbIaqFt6sTkVrqlK+mLL568gIgAPjFWrvAMyWePIUxOZ7CIjczVmYwbk4qq3ZkERNWh1vPacbQs5oSFujB9hTWQto8+PkV2PA9YIqbnzY/atF8CyeI+QV4rpbazlrYNNcZJVv7NbgLoVlvZ7SszSXgW0PalIhItVBhrS2qEoUxOZY8VxEfL9nG23M3smVvDs2jQxjVqzlXnNmIOn4ebE/hLnJ+4P/8inOlX0g0nDUaut6q9gtVwcEMWDoZlrznXH0aGus0kk0aDhFNvF2diNQCCmNS4x3IcTF5YRqT5qex+1ABZzSJYHTvRPq3i8XHx4ML2gvz4bePYP6rzlRkvWZw9l1wxlDwr8Fd+qsrd5EzYpnyDqyf5Vzs0LK/M1rWoh/4VMN+ciJSLZzqAn6RKi/9QC4T/7eJDxdtIbugiD6toxndO5GzmkV6tj1F3gGnEenCf8OhDGjQGQa/C+0u1w/0qszHF1oNcB77tzgjZb/+B9bPdKaTk4bBmTdBWKy3KxWRWkQjY1Itbcg8yLg5G/li2XbcFi7t1IBRvRNp2yDcsyc+mOEEsJR3ID8LmveBnvc6H2tTS4mapMjlTDGnvAOb5oCPH7QZ6IyWNeulv1cRqRAaGZMaY8nmfYybk8p3q3cS6O/D0G5NGXFuc5pEntw9Ek/anlT4eSz89qGzELzd5dDzHmh4pmfPK57n6w/tr3Aeu3+HJZOc9hirP3cutEi62Zl2Do70dqUiUkNpZEyqPGsts9dlMu6njSxK20tEsD839UhgWI946ofW8ezJty9xQtjqL8E3AM68Hnrc6VwVKTWXKxdWf+GMlm39BXzrQIcrndGyxl01WiYiJ00L+KVachW5+eq3HYyfs5F1Ow/SsG4gI85tzrXdmhAc4MFBXWsh9UfnyshNc517Ona9FbrfDqExnjuvVE0ZK5z1gcunOo15YztA8s3QcYjTdFZEpBw8GsaMMRuBdOAla+2np3Wwk6AwVnPlFBTy0aKtTJy3ie37c2kdG8ao3s25tHND/D154+6iQmdq6uexkLEcwhpA9zFO+wP90JX8g7DiE6dvWcYKCAh17oWZfAs06OTt6kSkivN0GPsJCMbp0L/BWtv+tA5YTgpjNc/e7AImzU/jPwvS2J/joltCJKP7NOe81jGevTLSleusEVrwunPj7fotnfVgnYaAn4enQaX6sdaZvk55B1Z+CoV50CjZCWXtB0GAh9cviki1VCnTlMaYYOBsa+33FXLAE1AYqzm27s1hwv82MjVlK3kuNxe0i2V070SS4j3cLDV3HyyaAL+Mg5zdzlqgnvdC64t170cpn9x9Tp+5lHdg93oIrPvHrZeiW3m7OhGpQrRmTKqkNelZjJuTyvTl6fgYuOKMRozq3ZwWMWGePfGBbbDgTeeqOVe20/Sz570Qf7YWZsupsRY2/wyLJ8Kar8DtgoRznbVlbS7Vba9E5PRbWxhjpgDjrLX/q9DKpNax1vLLpr2Mm5PKT+t2ERLgyy09E7jlnGY0qOvhjvWZa531YCumOT88Ow52piNjK2VmXWoyYyDhHOdxKNOZ9l7yLnxyi3NrrDNvdBrK1kvwdqUiUgWVa2SseJF+PLAOGAf8x1q738O1HZdGxqoXt9vy7eqdjJuTyrKt+6kfEsDNPRO4sXsCdYM9fMPmLb84V0au+wb8gqDLTdDjDqgX79nzSu3mdjtX5aa8A+tnOL8AtOjnrC1r2R981eZRpDapkGlKY8wAYBQwEHAB04Dx1tqFFVXoyVAYqx7yC4v4fOl2xs/dyMZd2TSNDOa2Xs25Oqkxgf6evHG3G37/1glhWxY4N+vuNgq6jYSQ+p47r8ixHNjm3HZpyXvO7bPCG0GXYc4vBuENvF2diFSCCl0zZoyJA24DbgWaAMuB8cD71tpDp1lruSmMVW0H81x88MsW3vl5Ezuz8mnfMJzRvRO5qEMcfh5tT+Fy2g/8PBZ2rXHuN9jjTuhyIwSEeO68IuVR5HLug5nyjjNqZnyhzcXFt17qowtHRGowjyzgN8Y0BD4AehVvOoQTyp601maf0kFPgsJY1ZR5MI93f07j/YWbOZhXSM8W9RndO5FzWkR5tj1F/iFn5GHBG5C1DWLaO+vBOlzp3O5GpKrZk/rHrZdy90K9Zs6C/zNu0OitSA1U0SNjfYHRwOU4AWwS8DFwKXA38K219qrTKbg8FMaqlrTd2bz1v418smQbriI3F3dowKjezenUOMKzJ87eDb+Mh0VvQd5+iO/pXBnZ8gJdGSnVQ2G+c7utlHdgy3zntlvtrnBGy5p21/exSA1REVdT1gduBkYCicASnED2obU2r3i3hcaYFcDE0y9ZqosV2w4wbk4q36xMx9/Xh6u6NGZkr+Y0i/LwlOC+NJj/ujOqUJgLbQY6IaxJV8+eV6Si+dWBTlc7j8w1Tij77SPnqt/otnD2nU7vMoUykRqrvJfzbAfcwFTgemvt4jL2WwtkVkRh3vblbzuYOG+Tt8uo0vJdRazNOEhYoB+jeydyc88EYsICPXvSjBXOerCVn4Hxgc7XwNl3Q3Rrz55XpDLEtIWLn4d+Tzrd/RdPgC/ugO2/wkXP6QpMkRqqvP+yHwPesdbuO95O1tplQLPTrqoKCPD1ISJIa42OxwT7M+jMRgw9qylhgR78s7IW0uY5V0Zu+N65J2D32532FOENPXdeEW8JCHGutDzjBvjhSecXkAPbYPA7UCfU29WJSAVTB36putxuWDvdCWHblzjNM88aDV1vdVpViNQWiyfANw9CXEcYOg3C4rxdkYicpIpYM/YyEGWtvfEYr00GdlprHzi9MkWKFeY7a2bmvwp7NjhXmV3yEpwxFPw93KVfpCrqOsJp0/LxzTChH1z/CcS08XZVIlJBytvU5jLg2zJemwVcUTHlSK2WlwXzXoFXOsFXdztTNYPfhbuWOKNhCmJSm7UaADd/DUUFMLE/bJrr7YpEpIKUd81YI2BrGa9tK35d5NQczICF/3auIsvPguZ9YNA456OuIBP5Q8MzYcT3MOVqmHwlXP6GcxGLiFRr5Q1j+4AWwE/HeK0FcLCiCpJaZE+qszD5tw/BXQjtLncatTY809uViVRdEU3hllkw9Qb470jYvwV6PaBfXESqsfKGse+Bx4wxX1lrdx7eaIyJBR4FvvNEcVJDbf/VWZS/+kunweUZ18PZd0H9RG9XJlI9BEXADZ/Cl3fB7P8H+zfDwJd1twmRaqq8YexxYDHwuzFmOn9MTQ4E8oG/eaY8qTGsde7F9/MrzlqXOnXhnPucqyPDYr1dnUj141cHBo13RsrmPg9ZO+DqSRAY7u3KROQklSuMWWvTjDFdgX8AFwD1gd3Af4G/W2s3e65EqdaKCmH15850ZMZyCGsAF/wfJA3XDw2R02UM9P2bE8i+uhfevQiu/1j990SqmXK3c7bWpgE3ea4UqVFcuc6tiha87ty6qH5LuOx16DTE+Y1eRCpOl5ucADZtmNP6Yug0iOvg7apEpJzK29pCpHxy98Gc5+HlDvDNA06j1mumwB2LoMuNCmIintKiH9wy01kS8M6FsOEHb1ckIuVU7pExY0wMcB3QGjj6BoTWWntrRRYm1cyB7bDwTUh5F1zZ0LK/c+Pu+LN1lZdIZYnr+Efriw+GwKVj4cwbvF2ViJxAeTvwtwYWAr5ACM56scji5/uAA54qUKq4zLVOp/zl08C6ocNVTnsKTZGIeEfdRnDLDGfK8os7YN9mOO9R/VIkUoWVd2TseWARTqf9bOAiYDnOGrKngEEeqc6bVn3u3A9OylaYB9sWg18QJN/i3Li7Xry3qxKRwLrOQv6v7oW5zzm9yC57DfwCvF2ZiBxDecNYV2A0ThsLAB9rbSHwjjEmCngFOM8D9XmRBXeRt4uo2nwDoPfD0G0khNT3djUiUpqvP1z+uvML0uyn4eAOGDLZ6VEmIlVKecNYKLDXWus2xhwAokq9lgI8UeGVeVv7Qc5DRKS6MgZ6/9VpffHFnc7C/us/hogm3q5MREop79WUaUBc8efrgKtLvTYQ2F+BNYmISEXqfK3TsT9rB0w4H3Ys83ZFIlJKecPYdzjNXgFeAm42xqwzxqwC7gHe8URxIiJSQZr3hltnOcsL3r0Y1n/r7YpEpFh5w9gjwAMA1tppwOU4t0daB9wO/N0j1YmISMWJaeu0vqifCB9eCyn6PVqkKjjhmjFjjC/QBthxeJu19ivgKw/WJSIinhAWBzfPgE9uhun3OVda9n0CfNQDXMRbyvOvz+Is0j/Tw7WIiEhlqBMK134ISTfDvJfhsxFQmH/i94mIR5xwZKz4CsqtOM1eRUSkJvD1g4EvO60vvn8SstLh2ikQHOntykRqnfKOS48H7jXGqGOgiEhNYQyccx9cNRG2p8DE/rB3k7erEql1yttnLAxIBDYaY2YC6TjTl4dZa60W8YuIVEcdB0NYA/hoKEy8AK6bCo2TvF2VSK1hrLUn3skY9wl2sdZa34opqXySk5NtSkpKZZ5SRKRm27UepgyGQ5kweCK0ucTbFYnUGMaYJdba5GO9Vq5pSmutzwkelRrERETEA6JbOa0vYtrCR9fDL+O9XZFIraBrmUVE5A+hMTB8OrS+GGb8FWY9Bu4TTY6IyOlQGBMRkSMFhMA1k6HbKFjwOnw8DFy53q5KpMYqVxgzxriNMUXHe/z/9u47zsrqzuP45weDNFFRsYEtRI0xlij2iIrYC4pixQIiidFodHVXo4llzW5M1DXqmhVRwRIFEbErdjEaFSyxJxYsiIoNEVHa2T+eyy4Zh+ECM3Punfm8X695Dfc+d+7z5XkJfD3Puec0dlBJUhNq1Rp2Px92/Q949Q4Yvg9M/yR3KqlZ+38r6wAAH6dJREFUKvfTlOfyz5+eBFgB2AVoCwxrwEySpEoQAVsfB8t2g9GDi09aHjaq2E5JUoMpq4yllM6u6/nSVkl3AFMbMJMkqZL8sE+x9MWNB8PQ3nDITbDGlrlTSc3GEs0ZSynNAS4HftkwcSRJFWn1LeDo+6H9cjB8b3h5TO5EUrPREBP42wLunyFJzd0K3eHoB2DVjeHmo+CJS6GMtSol1a/cCfxr1PH1/YjYF/gdxUbiZYmIkyLi5Yh4KSJujIh2EbFJRPw1Ip6PiPERscXi/oYkSY2o4wpw5O2w/t4w9sxi+Yu5foZLWhLlTuCfyHcn8AME8CZwXDlvEhFdgROAH6aUZkTESOBg4FDgnJTSPRGxB/B7YIcys0mSmlKb9tBvONz/62Lpi6nvw/5DiyUxJC2ycsvYQL5bxr4B3gGeKc0dW5Rzto+IWUAH4IPSey9TOr5s6TlJUqVq1Qp2/S10XqsYHRu2Jxw6slg0VtIiKffTlMMa4mQppUkRcQHwLjADGJtSGhsR7wH3lY61ArZpiPNJkhrZFsfAMl1h1EAYulOx9EWX9XKnkqpKuXPG1o2I7RdwrGdErFPm+3QG+gBrA6sBHSOiP3AscFJKaXXgJOCqBfz84NKcsvFTpkwp55SSpMb2gz1gwF3FKv1X7QwT/5I7kVRVyv005cXA3gs4thfwX2W+T2/g7ZTSlJTSLGA0xSjYkaVfA9wM1DmBP6U0JKXUI6XUo0uXLmWeUpLU6LpuVmwyvvTKcN2+8OKo3ImkqlFuGesBPLaAY48Bm5f5Pu8CW0VEh4gIYCfgVYo5YvNG3noB/yjz/SRJlaLzWjDwPui2OdxyNIy7yKUvpDKUO4G/E8WE/brMoph0v1AppaciYhTwLDAbeA4YUvr+x4ioKZ1ncJm5JEmVpMPycPitMObn8OA58MU7sMeF0Lrcf26klqfcPx1vUYxija3jWC+KpS/KklI6Czir1tOPA5uV+x6SpApW0xb6XgnLrQGPX1QsfdFvGLTtlDuZVJHKvU15LXBSRBwXEW0BIqJtRBxHsRXS8MYKKEmqQq1aQe+zYK+L4c2H4Zrd4cvJuVNJFancMnYBcDtwKTA9Ij4Gppce3w6c3zjxJElVrccAOHQEfPpWscn4R6/kTiRVnLLKWEppTkrpAIpPQ/4BGEOxSn6vlFK/lNLcRswoSapm6+wMA++BubPh6l3hrUdyJ5IqSqQq/aRLjx490vjxZW+JKUnK7Yv34IZ+8Ok/YJ9LYZNDcyeSmkxETEgp9ajrWLmLvu4VEccv4Nhxpf0kJUlasOVWh6PvgzW3hTHHwiPnu/SFRPlzxn4NLGgH2Pal45Ik1a/dssWWSRsfCo/8B9x2HMyemTuVlFW5ZewHFGuD1eV5YP2GiSNJavZqloJ9L4ftT4Pnb4A/94NvpuZOJWVTbhlrBSy9gGOdgDYNE0eS1CJEwI6nQ5/LYeLjcPXuxXpkUgtUbhl7AThsAccOA/7WMHEkSS3Kjw8rbltOfa9Y+mKy/5yo5Sm3jF0I9I2ImyNil4j4YUTsHBE3A/tRLHchSdKi674jDLwXolWxOOwbD+ROJDWpctcZuxU4EdgVuAd4Ebiv9PiElNLoRksoSWr+Vt4ABj0AndeGGw6ECW7sopaj7J1bU0qXRsQwYBtgBeAT4ImU0leNlE2S1JIss1qxOOzII+GOE4pNxnv9uphfJjVj5d6mBCClNC2ldF9K6c8ppbEppa8iYvuIuLqxAkqSWpC2nYrtkzY9AsZdCKOPgdnf5k4lNaqyR8bmFxHfB44ADgfWBL4GBjZgLklSS9W6Dex9CSy3Jjz078UG4wdfD+07504mNYqyR8YiYtmIGBwRjwOvA2cAnwPHAqs1Uj5JUksUAT1Pgb5XwntPwVW7wufv5E4lNYp6y1hEtIqIPSLiJmAy8D/AWsB/l17yy5TSFSmlLxs3piSpRdroQDj8Vvjqw2Lpi0kLWn9cql4LLGMRcQEwCbgD2Bu4FdgNWAP4DeCMSklS41t7Ozj6fqhpB8P2hNfvzZ1IalD1jYydDKwE3A2skVI6rDRpfy7gzq6SpKbTZb1i6YsV14WbDoGnr8ydSGow9ZWxq4FpwJ7A6xFxWURs0TSxJEmqpdPKMOBuWGcXuPsUGHsmzJ2bO5W0xBZYxlJKg4BVgP7ABOBnwJMR8Srwbzg6Jklqakt1hINugM0HwROXwqgBMOub3KmkJVLvBP6U0jelNcV2BVYHfgXMAU6jmDP2u4joHxHtGj+qJElA6xrY4wLY+d/hlTHFArHJ8QFVr7KXtkgpTU4pnZ9S+hGwJXA5sA5wLcUnLSVJahoRsO0JsMOv4G8j4JmhuRNJi22RVuCfJ6X0TErpeIr1xQ4AHm3QVJIklaPnqbDOrnDv6fDe07nTSItlscrYPCmlWSml0SmlfRsqkCRJZWvVCvpeAct2hZFHwFcf504kLbIlKmOSJGXXvjMcdD3M+BxGDYQ5s3MnkhaJZUySVP1W2RD2uhgmjoMHz8mdRlokljFJUvOwySGlJS8ugVduy51GKptlTJLUfOz6n9Btcxjzc5jyeu40UlksY5Kk5qNmKeg3HNq0hxH94dtpuRNJC2UZkyQ1L8t2hQOugU/fhNuOc0FYVTzLmCSp+Vl7O+h9djF37MnLcqeR6mUZkyQ1T9v8AtbfB+4/C94elzuNtECWMUlS8xQB+14OK3QvNhT/8oPciaQ6WcYkSc1X207FgrCzZsDII2H2zNyJpO+wjEmSmrcu60Gfy+D9p+G+X+VOI32HZUyS1PxtsB9sfTw8cyW8cFPuNNI/sYxJklqG3ufAmj+BO34JH76YO430fyxjkqSWoXUN9LsG2i9XLAg74/PciSTAMiZJakmWXgkOvBamToJbfwZz5+ZOJFnGJEktzOpbwG7/CX+/F8ZdmDuNZBmTJLVAmw+CjQ6Ch38LbzyQO41aOMuYJKnliYC9LoaVN4BbBsHn7+ROpBbMMiZJapmW6lDMH5s7F0YeXiwMK2VgGZMktVwrdIe+Q2DyC3DXKZBS7kRqgSxjkqSWbb3doOe/wvPXw7PDc6dRC2QZkyRph9Og+05w96kwaULuNGphLGOSJLVqDfsPhaVXgRFHwPRPcydSC2IZkyQJoMPycNC1MH0K3DIQ5s7JnUgthGVMkqR5Vvsx7HkhvPUIPHRe7jRqISxjkiTNb9PDYdMj4fGL4NU7c6dRC2AZkySptt1/X4ySjTkWPnkjdxo1c5YxSZJqa9MODrwOWtXAiP4wc3ruRGrGLGOSJNVludXhgKvhk9fh9hNcEFaNxjImSdKCdN8Rep0JL42Cp67InUbNlGVMkqT6bHsSrLcnjD0D3nkydxo1Q5YxSZLq06oV7PcnWG4NuPlImPZh7kRqZixjkiQtTLtl4aDr4dtpcPMAmDMrdyI1I5YxSZLKsfIGsM+l8O4TcP9vcqdRM2IZkySpXBseAFv+DP56Obw4KncaNROWMUmSFsUu58HqW8Htv4CPX82dRs2AZUySpEXRug0cOBzadioWhP1mau5EqnKWMUmSFlWnVaDfMPjsbRjzcxeE1RKxjEmStDjW3Ka4ZfnanfCXi3OnURWzjEmStLi2OhY26AsPngtvPZI7jaqUZUySpMUVUSx3seK6MGogfPFe7kSqQpYxSZKWRNuliwVhZ8+EkUfA7G9zJ1KVsYxJkrSkVlyn2DLpg2fhnn/LnUZVxjImSVJDWH9v+MlJMOEaeO763GlURSxjkiQ1lB3PhLW3hztPhg+ez51GVcIyJklSQ2ldAwdcDR1XhJGHw9ef5U6kKmAZkySpIXVcEQ68DqZ9CKOPgblzcidShbOMSZLU0LptBrufD288AI+enzuNKpxlTJKkxrDZANjksKKMvX5v7jSqYJYxSZIaQwTseSGsshHcOhg+eyt3IlUoy5gkSY2lTXs46DogYMQRMPPr3IlUgSxjkiQ1ps5rwf5D4aOX4M6TIKXciVRhmryMRcRJEfFyRLwUETdGRLvS87+IiNdLx37f1LkkSWo06+wMO5wOf7sJxl+VO40qTE1TniwiugInAD9MKc2IiJHAwRHxDtAH2Cil9G1ErNSUuSRJanQ9T4VJ4+Ge04p5ZKtvkTuRKkSO25Q1QPuIqAE6AB8AxwK/Syl9C5BS+jhDLkmSGk+rVtB3CCzbtdhQ/Cv/qVOhSctYSmkScAHwLjAZmJpSGgusC2wXEU9FxKMRsXlT5pIkqUm071wsCDvjcxg1EObMzp1IFaBJy1hEdKa4Hbk2sBrQMSL6U4yWdQa2Ak4FRkZE1PHzgyNifESMnzJlShMmlySpgay6Eex1MUwcBw+ekzuNKkBT36bsDbydUpqSUpoFjAa2Ad4HRqfC08BcYMXaP5xSGpJS6pFS6tGlS5cmDS5JUoPZ5BDYfBA8cQm8clvuNMqsqcvYu8BWEdGhNPK1E/AqMAboBRAR6wJLAZ80cTZJkprOrv8J3TaHMT+HKX/PnUYZNfWcsaeAUcCzwIul8w8Brga+FxEvATcBR6bkQiySpGasZinoNxxq2sGI/vDttNyJlElUa+fp0aNHGj9+fO4YkiQtmbcfg2v7wPr7QL9hxTZKanYiYkJKqUddx1yBX5KknNbuCb3PhlfGwJOX5U6jDCxjkiTlts0JsP7ecP9Z8Pa43GnUxCxjkiTlFgF9LocVusOoAfDlB7kTqQlZxiRJqgTtloGDrodZM2DkkTB7Zu5EaiKWMUmSKkWX9aDPZfD+0zD2jNxp1EQsY5IkVZIN9oOtj4enh8ALI3KnUROwjEmSVGl6nwNr/gTuOBE+fCl3GjUyy5gkSZWmdQ30uwbaL1csCDvji9yJ1IgsY5IkVaKlVypW6J/6Htz6U5g7N3ciNRLLmCRJlWqNLYs9LP9+L4y7MHcaNRLLmCRJlWyLY2Cjg+Dh38IbD+ROo0ZgGZMkqZJFwF4Xw8obwC2D4PN3cidSA7OMSZJU6ZbqAAdeW8wbG3k4zPomdyI1IMuYJEnVYIXu0PcKmPwC3H1K7jRqQJYxSZKqxXq7Q89T4bnrYMKw3GnUQCxjkiRVkx1Oh+694O5TYdKE3GnUACxjkiRVk1atYf+rYOlVYMQRMP3T3Im0hCxjkiRVmw7Lw0HXwvQpcMtAmDsndyItAcuYJEnVaLUfw54XwluPFGuQqWpZxiRJqlabHg6bHlmszv/aXbnTaDFZxiRJqma7/74YJbv1Z/Dpm7nTaDFYxiRJqmZt2hULwraqgRH9Yeb03Im0iCxjkiRVu+XWgAOugo9fhdtPgJRyJ9IisIxJktQcdO8Fvc6El0bBU1fkTqNFYBmTJKm5+MnJsN4eMPYMeOfJ3GlUJsuYJEnNRatWsN//FLctbz4Spn2YO5HKYBmTJKk5abcsHHQ9fDsNbh4Ac2blTqSFsIxJktTcrLwB7HMpvPsE3PNvMHdu7kSqR03uAJIkqRFseABMfgGeuASmvgd9h0D7zrlTqQ6OjEmS1FztfC7seRG8+TAM2QE+fDF3ItXBMiZJUnMVAZsfDQPugdkzYejO8MKI3KlUi2VMkqTmbvXN4aePQrcecOtguOuUopypIljGJElqCZZeCQ4fA1sfD89cCcP3gi8n504lLGOSJLUcrWtg19/CAdfAhy/BFT1h4l9yp2rxLGOSJLU0P+oLxzwE7ZaB4XvDk5e7n2VGljFJklqilX4AxzwM6+0O950OtwyCmdNzp2qRLGOSJLVU7ZYpVuvf6Sx4eTQM7Q2fvpk7VYtjGZMkqSWLgO1Ohv6ji70sh+wAr9+TO1WLYhmTJEnQfcdi+Yvlvwc3HgwPnQdz5+RO1SJYxiRJUmG5NWDgffDjw+GxP8AN/eDrz3KnavYsY5Ik6f+1aQd9LoO9/wgTx8GQ7Ys9LtVoLGOSJOm7NjsKBtwLc+fCVbvA83/OnajZsoxJkqS6ddusmEe2+hYw5li48ySY/W3uVM2OZUySJC1YxxWh/62w7Ykw/mq4Zg+YOil3qmbFMiZJkurXugZ2PhcOvBamvFbMI3t7XO5UzYZlTJIkleeHfYptlNp3hmv7wBOXuo1SA7CMSZKk8nVZryhkP9gTxp4JowbAt1/lTlXVLGOSJGnRtO1U3LLc+Vx45TYYuhN88o/cqaqWZUySJC26iGJS/+FjYPoUGLIjvHpH7lRVyTImSZIW3/e2h58+Bl3WhRH94YFz3EZpEVnGJEnSklm2Gwy4p1go9vGL4Pr9YfqnuVNVDcuYJElacjVtiy2U9rkM3nmiWP7ig+dyp6oKljFJktRwNj0cBt5b/PqqXeHZ6/LmqQKWMUmS1LC6bgqDH4U1t4bbj4c7TnQbpXpYxiRJUsPruAL0Hw0/ORkmDIOrd4Op7+dOVZEsY5IkqXG0ag29z4KDbijWIbuiJ7z1aO5UFccyJkmSGtf6e8Hgh6FjF7huX3j8YrdRmo9lTJIkNb4V14FBD8L6+8ADZ8HII+DbablTVQTLmCRJahptl4Z+w2CX8+C1u+DKXjDl9dypsrOMSZKkphMB2/wCjrgNvv6sKGSv3JY7VVaWMUmS1PTW3q7YRmml9YtblmN/DXNm506VhWVMkiTlsWxXOOou6HE0PHEJXL8fTP8kd6omZxmTJEn51LSFvS6Cff8E7z1dLH/x/oTcqZqUZUySJOW3yaFw9NhibbJrdisWim0hLGOSJKkyrLpxsY3SWtsVWyjddjzM+iZ3qkZnGZMkSZWjw/Jw2M3Q81R47jq4elf44t3cqRqVZUySJFWWVq2h15lw8I3w2Vtwxfbw5kO5UzUay5gkSapMP9gDBj8CnVaB6/eHcRc2y22ULGOSJKlyrdAdBj0AG/SFB8+FEf3hmy9zp2pQljFJklTZluoI+w+F3X4Hr98DV+4IH7+WO1WDsYxJkqTKFwFbHQtH3lGMjF3ZC14anTtVg7CMSZKk6rHWtsU2SitvAKMGwH1nVP02SpYxSZJUXZZZtdhGafNj4MnL4No+8NXHuVMtNsuYJEmqPjVLwZ4XwH5XwKQJxfIX7z2TO9VisYxJkqTqtfHBMOj+opxdszs8M7Tqlr+wjEmSpOq2yobFemTdd4S7/gXG/BxmzcidqmyWMUmSVP3ad4ZDRsD2p8ELf4ardoHPJ+ZOVZYmL2MRcVJEvBwRL0XEjRHRbr5jp0REiogVmzqXJEmqcq1awY6nw6Ej4Yt3inlkbzyQO9VCNWkZi4iuwAlAj5TSj4DWwMGlY6sDOwPNezdQSZLUuNbdtbhtuWw3uP4AePQPMHdu7lQLlOM2ZQ3QPiJqgA7AB6Xn/wv4V6C6Zt1JkqTKs/z34Oj7YcN+8PB5cNOhMOOL3Knq1KRlLKU0CbiAYvRrMjA1pTQ2IvYBJqWUXmjKPJIkqRlbqgP0HQK7/wHeuL/YRumjV3Kn+o6mvk3ZGegDrA2sBnSMiCOAM4DflPHzgyNifESMnzJlSuOGlSRJ1S8CthxcLBI782sYuhO8OCp3qn/S1LcpewNvp5SmpJRmAaOBARTl7IWImAh0A56NiFVq/3BKaUhKqUdKqUeXLl2aMrckSapma2wFP30UVt0Ybjka7jkN5szKnQpo+jL2LrBVRHSIiAB2AkanlFZKKa2VUloLeB/YNKX0YRNnkyRJzVmnVYqNxrc8Fp76EwzfB6Z9lDtVk88ZewoYBTwLvFg6/5CmzCBJklqw1m1g999B36HwwXNwRc/s2yjVNPUJU0pnAWfVc3ytpksjSZJapI36wUrrwy2DivXJMmryMiZJklQRVvkRHPtE9jLmdkiSJKnlylzEwDImSZKUlWVMkiQpI8uYJElSRpYxSZKkjCxjkiRJGVnGJEmSMrKMSZIkZWQZkyRJysgyJkmSlJFlTJIkKSPLmCRJUkaWMUmSpIwsY5IkSRlZxiRJkjKyjEmSJGVkGZMkScrIMiZJkpRRpJRyZ1gsETEFeKeRT7Mi8Ekjn6PaeY3q5/VZOK9R/bw+C+c1qp/XZ+Ga4hqtmVLqUteBqi1jTSEixqeUeuTOUcm8RvXz+iyc16h+Xp+F8xrVz+uzcLmvkbcpJUmSMrKMSZIkZWQZq9+Q3AGqgNeofl6fhfMa1c/rs3Beo/p5fRYu6zVyzpgkSVJGjoxJkiRlZBmrQ0RcHREfR8RLubNUoohYPSIejohXI+LliDgxd6ZKExHtIuLpiHihdI3OyZ2pEkVE64h4LiLuzJ2lEkXExIh4MSKej4jxufNUmohYLiJGRcRrpb+Pts6dqZJExHql/3bmfX0ZEb/MnauSRMRJpb+jX4qIGyOiXZYc3qb8rojoCXwFXJtS+lHuPJUmIlYFVk0pPRsRnYAJwL4ppVcyR6sYERFAx5TSVxHRBngcODGl9NfM0SpKRJwM9ACWSSntlTtPpYmIiUCPlJJrRNUhIoYD41JKQyNiKaBDSumL3LkqUUS0BiYBW6aUGnuNzqoQEV0p/m7+YUppRkSMBO5OKQ1r6iyOjNUhpfQY8FnuHJUqpTQ5pfRs6dfTgFeBrnlTVZZU+Kr0sE3py//zmU9EdAP2BIbmzqLqExHLAD2BqwBSSjMtYvXaCXjTIvYdNUD7iKgBOgAf5AhhGdMSiYi1gB8DT+VNUnlKt+CeBz4G7k8peY3+2cXAvwJzcwepYAkYGxETImJw7jAV5nvAFOCa0q3uoRHRMXeoCnYwcGPuEJUkpTQJuAB4F5gMTE0pjc2RxTKmxRYRSwO3AL9MKX2ZO0+lSSnNSSltAnQDtogIb3mXRMRewMcppQm5s1S4bVNKmwK7A8eVplCoUANsCvwppfRjYDpwWt5Ilal0C3cf4ObcWSpJRHQG+gBrA6sBHSOif44sljEtltI8qFuAG1JKo3PnqWSlWyePALtljlJJtgX2Kc2JugnoFRHX541UeVJKH5S+fwzcCmyRN1FFeR94f74R51EU5UzftTvwbErpo9xBKkxv4O2U0pSU0ixgNLBNjiCWMS2y0uT0q4BXU0oX5c5TiSKiS0QsV/p1e4o/9K/lTVU5Ukqnp5S6pZTWorh98lBKKcv/kVaqiOhY+oAMpdtvuwB+wrskpfQh8F5ErFd6aifADxHV7RC8RVmXd4GtIqJD6d+1nSjmQDc5y1gdIuJG4ElgvYh4PyKOzp2pwmwLHE4xmjHvI9N75A5VYVYFHo6IvwHPUMwZc/kGLYqVgccj4gXgaeCulNK9mTNVml8AN5T+nG0C/EfmPBUnIjoAO1OM+mg+pVHVUcCzwIsUnSjLSvwubSFJkpSRI2OSJEkZWcYkSZIysoxJkiRlZBmTJEnKyDImSZKUkWVMUqOLiFTG18TcOWsr5Tq7Ed9/h4g4OyJa1Xp+rdK5BzXWuSVVjprcASS1CFvXenwr8AJw9nzPfdtkaSrHDsBZwHm4R6fUYlnGJDW6lNJf538cEd8Cn9R+vtZrWlOshTi7sfNJUk7eppRUEUq35X4bEadFxNvATGDD0rHtI+LBiJgWEdMj4r66Nl6PiL4R8deI+DoivoiImyNijTLO3ToizouIyaWffSQiNljAazeOiNsj4vOImBERf4mI7Wq9Zlhp945tIuKZiPgmIiZGxC/me83ZFKNiALPm3a6tdbrWEXFuKdcXEXFHRHRb2O9HUnWxjEmqJEcBewKnlL5/EBF7Ag8CXwH9gUOBTsC4iFh93g9GxM8oNq9/BTgA+CnwI+DReXs81uNs4FfADcC+wFjg9toviohNgSeA5YFjgP2BT4EHImKzWi9fBhgBDC+95yPAJRFxVOn4UIo9XgF+QnErt/bt3NOB7wMDgRNLx29YyO9FUpXxNqWkShLALimlGf/3RMQfgUdTSn3me+5h4C3gX4BfRsTSwPnANSmlgfO97ing78DRwMV1njCiM3ASMCSldErp6bERMQf4Xa2X/4Fic+FeKaWZpZ+/j2ID719TlK55OgGDU0o3lR7fGxFdgXMiYnhK6f2IeL907KkF3I59J6V06HxZuwB/iIjVUkof1PX7kVR9HBmTVEnurVXE1gG6U2wGXTPvC/gaeBLoWXrp1hQjUbVf9z7w2nyvq8uGQEdgZK3nb5r/QUS0B7YHbgbmzneOAB6o4xxzKEbqar/nGkDXevLM765aj18sfV/orVdJ1cORMUmVZHKtxyuVvl/F/9/Sm9+7tV73wALe9/N6zrlq6ftHtZ6v/Xh5oDXFCNiv63qjiGiVUpr3qcjPU0qzFvCeXSmK4sJ8VuvxvE+ctivjZyVVCcuYpEpSewL7p6Xvp1N30ZpZ63VHAS/X8bpp9ZxzXgFcudbPrlzrdV9QLD/x38C1db3RfEUMoHNEtKlVyOa956R68khqYSxjkirZ68BEYIOUUu35W/N7gqJwfT+lNHwRz/E3YDpwIPDQfM8fPP+LUkrTI2IcsDHwbK3iVZfWFBP857/deTDFaN68MjZvpKs99RdGSc2YZUxSxUoppYg4DrgtIpaimNf1CcUI0zbAuymli1JKX0bEqcB/lya53wNMpbgduD3wSErpzws4xxcR8V/AGRExjeKTlJtTTPqv7WTgMeC+iLiKYlRtRWBToHVK6bT5XjsN+H1ErAj8AzgE6A0clVKaNwL4Sun7v0TEPcCclNL4Rb1OkqqbZUxSRUsp3R0RPYEzKJaDaA98CPyVYumIea+7IiLeA06lWP6iDcUI1GPA8ws5zdkUE/EHAccDTwF7U+uWZ0rp2YjYnGJ9sEuAZYEpwLPA/9R6zy8pRsL+SPEhgY+AE2uN3N0JXA78HPhNKUMsJKukZib+/3/QJEkNISKGAb1TSi7QKmmhXNpCkiQpI8uYJElSRt6mlCRJysiRMUmSpIwsY5IkSRlZxiRJkjKyjEmSJGVkGZMkScrIMiZJkpTR/wJLnzXy2sGpkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(max_depths, accuracies_train, label=\"Train\") \n",
    "plt.plot(max_depths, accuracies_test, label=\"Test\") \n",
    "\n",
    "i=np.argmax(accuracies_test)\n",
    "plt.plot(max_depths[i], accuracies_test[i], label=\"Best={0:.3}%\".format(accuracies_test[i]), \n",
    "         marker='o', markersize=10, markerfacecolor='red', markeredgecolor='black') \n",
    "\n",
    "plt.legend(prop={'size':14})\n",
    "plt.ylabel('Accuracy, %', size=16)\n",
    "plt.xlabel('Tree depth', size=16)\n",
    "plt.title(\"Pruning by depth\", size=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min Samples Split\n",
    "\n",
    "(15 points)\n",
    "\n",
    "Consider the following min_samples_split values: [1, 5, 10, 20, 50]. For each value, construct a tree and prune it according to the min_samples_split value = don't split a node if the number of sample in it is less or equal to the min_samples_split value. Next, calculate the training and testing accuracy.<br>\n",
    "On a single plot, draw the training and testing accuracy as a function of the min_samples_split. Mark the best result on the graph with red circle. (make sure that the x-axis ticks represent the values of min_samples_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your code here ####\n",
    "# essentially the same code as above, just this time we iterate over min_samples_split:\n",
    "\n",
    "min_splits = np.array([1, 5, 10, 20, 50])\n",
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "for ms in min_splits: \n",
    "    pruned_tree = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, min_samples_split = ms) # entropy with gain ratio\n",
    "    accuracies_train.append(calc_accuracy(pruned_tree, X_train))\n",
    "    accuracies_test.append(calc_accuracy(pruned_tree, X_test))\n",
    "                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(min_splits, accuracies_train, label=\"Train\") \n",
    "plt.plot(min_splits, accuracies_test, label=\"Test\") \n",
    "\n",
    "i=np.argmax(accuracies_test)\n",
    "plt.plot(min_splits[i], accuracies_test[i], label=\"Best={0:.3}%\".format(accuracies_test[i]), \n",
    "         marker='o', markersize=10, markerfacecolor='red', markeredgecolor='black') \n",
    "\n",
    "plt.legend(prop={'size':14})\n",
    "plt.ylabel('Accuracy, %', size=16)\n",
    "plt.xlabel('Min samples in a leaf', size=16)\n",
    "plt.title(\"Pruning by min samples\", size=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the best 2 trees:\n",
    "1. tree_max_depth - the best tree according to max_depth pruning\n",
    "1. tree_min_samples_split - the best tree according to min_samples_split pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your code here ####\n",
    "tree_max_depth = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, max_depth= 4) \n",
    "tree_min_samples_split = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, min_samples_split = 50) # entropy with gain ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Nodes\n",
    "\n",
    "(5 points)\n",
    "\n",
    "Complete the function counts_nodes and print the number of nodes in each tree and print the number of nodes of the two trees above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nodes(node):\n",
    "    \"\"\"\n",
    "    Count the number of node in a given tree\n",
    " \n",
    "    Input:\n",
    "    - node: a node in the decision tree.\n",
    " \n",
    "    Output: the number of node in the tree.\n",
    "    \"\"\"\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    n = 0\n",
    "    # count nodes in the children (each child will return at least 1 if it has \n",
    "    # no children of its own:\n",
    "    for ch in node.children:\n",
    "        n+=count_nodes(ch)\n",
    "    return n+1 # count the current node (that's what +1 is for) and return\n",
    "    \n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth tree: 205 nodes\n",
      "Min samples tree: 349 nodes\n"
     ]
    }
   ],
   "source": [
    "print(\"Max depth tree:\", count_nodes(tree_max_depth), \"nodes\")\n",
    "print(\"Min samples tree:\", count_nodes(tree_min_samples_split), \"nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the tree\n",
    "\n",
    "Complete the function `print_tree`. Your tree should be visualized clearly. You can use the following example as a reference:\n",
    "```\n",
    "[ROOT, feature=X0],\n",
    "  [X0=a, feature=X2]\n",
    "    [X2=c, leaf]: [{1.0: 10}]\n",
    "    [X2=d, leaf]: [{0.0: 10}]\n",
    "  [X0=y, feature=X5], \n",
    "    [X5=a, leaf]: [{1.0: 5}]\n",
    "    [X5=s, leaf]: [{0.0: 10}]\n",
    "  [X0=e, leaf]: [{0.0: 25, 1.0: 50}]\n",
    "```\n",
    "In each brackets:\n",
    "* The first argument is the parent feature with the value that led to current node\n",
    "* The second argument is the selected feature of the current node\n",
    "* If the current node is a leaf, you need to print also the labels and their counts\n",
    "\n",
    "(5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can change the function signature\n",
    "def print_tree(node, depth=0, parent_feature='ROOT', feature_val='ROOT'):\n",
    "    '''\n",
    "    prints the tree according to the example above\n",
    "\n",
    "    Input:\n",
    "    - node: a node in the decision tree\n",
    "\n",
    "    This function has no return value\n",
    "    '''\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the function.                                           #\n",
    "    ###########################################################################\n",
    "    print(\" \"*2*depth, end='')\n",
    "    print(\"[X\",parent_feature, end='', sep=\"\")\n",
    "    if feature_val != 'ROOT':\n",
    "        print(\"=\", feature_val,end='', sep=\"\")\n",
    "    if node.feature is None and len(node.children) > 0 or \\\n",
    "       node.feature is not None and len(node.children) == 0:\n",
    "            raise RuntimeError(\"Inconsistent node: \", str(node))\n",
    "    if node.feature is None: # it's a leaf!\n",
    "        print(\", leaf]: [{\", end='')\n",
    "        print(\", \".join([\"{0}: {1}\".format(cls, cnt) for cls, cnt in zip(node.counts[0], node.counts[1])]), \"}]\", end=\"\")\n",
    "    else:\n",
    "        print(\", feature=X\",node.feature,\"]\", end=\"\", sep=\"\")\n",
    "    print()\n",
    "    for ch in node.children:\n",
    "        print_tree(ch, depth=depth+1, parent_feature=node.feature, feature_val=ch.split_value)\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the tree with the best test accuracy and with less than 50 nodes (from the two pruning methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best depth-pruned model with n < 50 nodes: MaxDepth=1; Test accuracy=88.52781880846874\n",
      "The best min split size-pruned model with n < 50 nodes: MinSplitSize=450; Test accuracy=89.31560807483999\n",
      "-----------------------------------------\n",
      "Best tree with n<50 nodes:\n",
      "-----------------------------------------\n",
      "[XROOT, feature=X4]\n",
      "  [X4=a, leaf]: [{e: 273, p: 31 }]\n",
      "  [X4=c, leaf]: [{e: 10, p: 137 }]\n",
      "  [X4=f, feature=X10]\n",
      "    [X10=f, leaf]: [{e: 14, p: 91 }]\n",
      "    [X10=k, feature=X11]\n",
      "      [X11=k, feature=X7]\n",
      "        [X7=b, feature=X19]\n",
      "          [X19=v, feature=X20]\n",
      "            [X20=d, leaf]: [{e: 10, p: 144 }]\n",
      "            [X20=g, leaf]: [{e: 18, p: 140 }]\n",
      "            [X20=p, leaf]: [{e: 18, p: 139 }]\n",
      "          [X19=y, feature=X2]\n",
      "            [X2=g, leaf]: [{e: 27, p: 223 }]\n",
      "            [X2=y, leaf]: [{e: 39, p: 208 }]\n",
      "        [X7=n, leaf]: [{e: 6, p: 97 }]\n",
      "      [X11=s, leaf]: [{e: 16, p: 86 }]\n",
      "    [X10=s, leaf]: [{e: 22, p: 310 }]\n",
      "  [X4=l, leaf]: [{e: 272, p: 27 }]\n",
      "  [X4=m, leaf]: [{e: 2, p: 25 }]\n",
      "  [X4=n, feature=X7]\n",
      "    [X7=b, feature=X18]\n",
      "      [X18=b, leaf]: [{e: 34, p: 2 }]\n",
      "      [X18=k, feature=X11]\n",
      "        [X11=f, leaf]: [{e: 126, p: 19 }]\n",
      "        [X11=s, feature=X1]\n",
      "          [X1=f, leaf]: [{e: 358, p: 43 }]\n",
      "          [X1=s, leaf]: [{e: 68, p: 2 }]\n",
      "          [X1=y, leaf]: [{e: 291, p: 29 }]\n",
      "      [X18=n, feature=X15]\n",
      "        [X15=n, leaf]: [{e: 14, p: 4 }]\n",
      "        [X15=o, leaf]: [{e: 18, p: 1 }]\n",
      "        [X15=w, feature=X8]\n",
      "          [X8=h, leaf]: [{e: 68, p: 8 }]\n",
      "          [X8=k, leaf]: [{e: 71, p: 5 }]\n",
      "          [X8=n, leaf]: [{e: 218, p: 22 }]\n",
      "          [X8=p, leaf]: [{e: 215, p: 18 }]\n",
      "          [X8=u, leaf]: [{e: 138, p: 21 }]\n",
      "          [X8=w, leaf]: [{e: 140, p: 26 }]\n",
      "      [X18=o, leaf]: [{e: 28, p: 4 }]\n",
      "      [X18=r, leaf]: [{e: 6, p: 46 }]\n",
      "      [X18=w, leaf]: [{e: 369, p: 33 }]\n",
      "      [X18=y, leaf]: [{e: 35, p: 3 }]\n",
      "    [X7=n, leaf]: [{e: 135, p: 58 }]\n",
      "  [X4=p, leaf]: [{e: 8, p: 175 }]\n",
      "  [X4=s, leaf]: [{e: 38, p: 380 }]\n",
      "  [X4=y, leaf]: [{e: 49, p: 382 }]\n"
     ]
    }
   ],
   "source": [
    "#### Your code here ####\n",
    "\n",
    "# the best trees we found so far are too big (have > 50 nodes) - let's search again, this time for the best tree\n",
    "# with the additional constraint of < 50 nodes:\n",
    "\n",
    "max_depths = np.array(range(1,6))\n",
    "acctest_depth = []\n",
    "for md in max_depths: \n",
    "    ptree = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, max_depth= md) # entropy with gain ratio\n",
    "    if count_nodes(ptree) >=50: \n",
    "        acctest_depth.append(0) # oops, tree is too big\n",
    "    else: \n",
    "        acctest_depth.append(calc_accuracy(ptree, X_test))\n",
    "\n",
    "min_splits = np.array([50, 75, 100, 150, 200, 300, 350, 400, 450,  500])\n",
    "\n",
    "acctest_split = []\n",
    "for ms in min_splits: \n",
    "    ptree = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, min_samples_split = ms) # entropy with gain ratio\n",
    "    if count_nodes(ptree) >=50: \n",
    "        acctest_split.append(0) # oops, tree is too big\n",
    "    else: \n",
    "        acctest_split.append(calc_accuracy(ptree, X_test))\n",
    "\n",
    "i_d=np.argmax(acctest_depth)\n",
    "i_s=np.argmax(acctest_split)\n",
    "print(\"The best depth-pruned model with n < 50 nodes: MaxDepth=\",max_depths[i_d],\"; Test accuracy=\",acctest_depth[i_d], sep='')        \n",
    "print(\"The best min split size-pruned model with n < 50 nodes: MinSplitSize=\",min_splits[i_s],\"; Test accuracy=\",acctest_split[i_s], sep='')        \n",
    "\n",
    "# refit the best model\n",
    "best_tree_n50 = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, min_samples_split = 450)\n",
    "\n",
    "print(\"-----------------------------------------\\nBest tree with n<50 nodes:\\n-----------------------------------------\")\n",
    "\n",
    "print_tree(best_tree_n50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best depth-pruned model with n < 50 nodes: MaxDepth=1; Test accuracy=88.52781880846874\n",
      "The best min split size-pruned model with n < 50 nodes: MinSplitSize=1; Test accuracy=0\n",
      "-----------------------------------------\n",
      "Best tree with n<50 nodes:\n",
      "-----------------------------------------\n",
      "[XROOT, feature=X4]\n",
      "  [X4=a, leaf]: [{e: 273, p: 31 }]\n",
      "  [X4=c, leaf]: [{e: 10, p: 137 }]\n",
      "  [X4=f, feature=X10]\n",
      "    [X10=f, leaf]: [{e: 14, p: 91 }]\n",
      "    [X10=k, feature=X11]\n",
      "      [X11=k, feature=X7]\n",
      "        [X7=b, feature=X19]\n",
      "          [X19=v, feature=X20]\n",
      "            [X20=d, leaf]: [{e: 10, p: 144 }]\n",
      "            [X20=g, leaf]: [{e: 18, p: 140 }]\n",
      "            [X20=p, leaf]: [{e: 18, p: 139 }]\n",
      "          [X19=y, feature=X2]\n",
      "            [X2=g, leaf]: [{e: 27, p: 223 }]\n",
      "            [X2=y, leaf]: [{e: 39, p: 208 }]\n",
      "        [X7=n, leaf]: [{e: 6, p: 97 }]\n",
      "      [X11=s, leaf]: [{e: 16, p: 86 }]\n",
      "    [X10=s, leaf]: [{e: 22, p: 310 }]\n",
      "  [X4=l, leaf]: [{e: 272, p: 27 }]\n",
      "  [X4=m, leaf]: [{e: 2, p: 25 }]\n",
      "  [X4=n, feature=X7]\n",
      "    [X7=b, feature=X18]\n",
      "      [X18=b, leaf]: [{e: 34, p: 2 }]\n",
      "      [X18=k, feature=X11]\n",
      "        [X11=f, leaf]: [{e: 126, p: 19 }]\n",
      "        [X11=s, feature=X1]\n",
      "          [X1=f, leaf]: [{e: 358, p: 43 }]\n",
      "          [X1=s, leaf]: [{e: 68, p: 2 }]\n",
      "          [X1=y, leaf]: [{e: 291, p: 29 }]\n",
      "      [X18=n, feature=X15]\n",
      "        [X15=n, leaf]: [{e: 14, p: 4 }]\n",
      "        [X15=o, leaf]: [{e: 18, p: 1 }]\n",
      "        [X15=w, feature=X8]\n",
      "          [X8=h, leaf]: [{e: 68, p: 8 }]\n",
      "          [X8=k, leaf]: [{e: 71, p: 5 }]\n",
      "          [X8=n, leaf]: [{e: 218, p: 22 }]\n",
      "          [X8=p, leaf]: [{e: 215, p: 18 }]\n",
      "          [X8=u, leaf]: [{e: 138, p: 21 }]\n",
      "          [X8=w, leaf]: [{e: 140, p: 26 }]\n",
      "      [X18=o, leaf]: [{e: 28, p: 4 }]\n",
      "      [X18=r, leaf]: [{e: 6, p: 46 }]\n",
      "      [X18=w, leaf]: [{e: 369, p: 33 }]\n",
      "      [X18=y, leaf]: [{e: 35, p: 3 }]\n",
      "    [X7=n, leaf]: [{e: 135, p: 58 }]\n",
      "  [X4=p, leaf]: [{e: 8, p: 175 }]\n",
      "  [X4=s, leaf]: [{e: 38, p: 380 }]\n",
      "  [X4=y, leaf]: [{e: 49, p: 382 }]\n"
     ]
    }
   ],
   "source": [
    "# It appears an update was posted toward the end of submission on piazza \n",
    "# So per the update for max depth 1-8 and min splits 1,5,10,20,50 here is the output\n",
    "# I finished a long time ago and so just updated the code with the values\n",
    "# As you can see however, the test accuracy is consistent regardless\n",
    "\n",
    "max_depths = np.array(range(1,9)) #[start,stop)\n",
    "acctest_depth = []\n",
    "for md in max_depths: \n",
    "    ptree = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, max_depth= md) # entropy with gain ratio\n",
    "    if count_nodes(ptree) >=50: \n",
    "        acctest_depth.append(0) # oops, tree is too big\n",
    "    else: \n",
    "        acctest_depth.append(calc_accuracy(ptree, X_test))\n",
    "\n",
    "min_splits = np.array([1,5,10,20,50])\n",
    "\n",
    "acctest_split = []\n",
    "for ms in min_splits: \n",
    "    ptree = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, min_samples_split = ms) # entropy with gain ratio\n",
    "    if count_nodes(ptree) >=50: \n",
    "        acctest_split.append(0) # oops, tree is too big\n",
    "    else: \n",
    "        acctest_split.append(calc_accuracy(ptree, X_test))\n",
    "\n",
    "i_d=np.argmax(acctest_depth)\n",
    "i_s=np.argmax(acctest_split)\n",
    "print(\"The best depth-pruned model with n < 50 nodes: MaxDepth=\",max_depths[i_d],\"; Test accuracy=\",acctest_depth[i_d], sep='')        \n",
    "print(\"The best min split size-pruned model with n < 50 nodes: MinSplitSize=\",min_splits[i_s],\"; Test accuracy=\",acctest_split[i_s], sep='')        \n",
    "\n",
    "# refit the best model\n",
    "best_tree_n50 = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True, min_samples_split = 450)\n",
    "\n",
    "print(\"-----------------------------------------\\nBest tree with n<50 nodes:\\n-----------------------------------------\")\n",
    "\n",
    "print_tree(best_tree_n50)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
